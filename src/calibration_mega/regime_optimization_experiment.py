"""
Multi-Regime Parameter Studies for Optimization Landscape Analysis

This module implements comprehensive parameter regime studies to analyze calibration
performance across different OU process parameter spaces.

Author: Bryson Schenck
Date: January 2025
"""

import torch
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for thread safety
import matplotlib.pyplot as plt
import pandas as pd
import os
import sys
import time
import warnings
from scipy import stats
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

sys.path.append('.')

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Suppress specific warnings
warnings.filterwarnings('ignore', message='.*degrees of freedom is <= 0.*')
warnings.filterwarnings('ignore', message='.*output with one or more elements was resized.*')
warnings.filterwarnings('ignore', category=UserWarning, module='torch.autograd')

from src.numerical.paths import generate_ou_process
from src.numerical.parameters import generate_ou_parameters_for_regime
from src.calibration_mega.signatures import compute_parameter_mse
from src.calibration_mega.optimization_landscape_experiment import EnhancedOptimizationLandscapeExperiment
from src.calibration_mega.parameter_management import OptimizationParams
from src.calibration_mega.experiment_config import ExperimentConfig, ConfigPresets

# Phase 5 optimized imports
try:
    from src.analytical.expected_signature_optimized import (
        clear_generator_cache,
        get_cache_stats
    )
    OPTIMIZATIONS_AVAILABLE = True
    logger.info("Phase 5 optimizations loaded successfully")
except ImportError as e:
    OPTIMIZATIONS_AVAILABLE = False
    logger.warning(f"Phase 5 optimizations not available: {e}")


@dataclass
class RegimeResults:
    """Container for results from Enhancement Cascade Architecture: Analytical â†’ Enhanced MLE â†’ Signatures â†’ MoM."""
    regime_name: str
    
    # Phase 0: Analytical OU K* Selection and Smart Initialization
    analytical_ou_mse: Dict[int, List[float]] = field(default_factory=dict)
    analytical_ou_convergence: Dict[int, List[float]] = field(default_factory=dict)  # Convergence rate
    analytical_ou_time: Dict[int, List[float]] = field(default_factory=dict)
    
    # Track K* selections and initialization parameters
    optimal_k_star: List[int] = field(default_factory=list)  # K* from each MC run
    analytical_ou_optimal_params: List[Tuple] = field(default_factory=list)  # Initialization params
    
    # Phase 1: Enhanced MLE with Smart Initialization (single K* per simulation)
    enhanced_mle_mse: List[float] = field(default_factory=list)
    enhanced_mle_K: List[int] = field(default_factory=list)  # Should all be K*
    enhanced_mle_convergence: List[bool] = field(default_factory=list)
    enhanced_mle_time: List[float] = field(default_factory=list)
    enhanced_mle_enhancement_rate: List[bool] = field(default_factory=list)  # Track actual enhancements
    
    # Phase 2: Signature Methods with Smart Initialization
    expected_sig_mse: Dict[int, List[float]] = field(default_factory=dict)
    rescaled_sig_mse: Dict[int, List[float]] = field(default_factory=dict)
    expected_sig_convergence: Dict[int, List[bool]] = field(default_factory=dict)
    rescaled_sig_convergence: Dict[int, List[bool]] = field(default_factory=dict)
    expected_sig_time: Dict[int, List[float]] = field(default_factory=dict)
    rescaled_sig_time: Dict[int, List[float]] = field(default_factory=dict)
    expected_sig_enhancement_rate: Dict[int, List[bool]] = field(default_factory=dict)  # Track actual enhancements
    rescaled_sig_enhancement_rate: Dict[int, List[bool]] = field(default_factory=dict)  # Track actual enhancements
    
    # Phase 3: Method of Moments Comprehensive Baseline
    method_of_moments_mse: Dict[int, List[float]] = field(default_factory=dict)
    method_of_moments_convergence: Dict[int, List[float]] = field(default_factory=dict)  # Convergence rate
    method_of_moments_time: Dict[int, List[float]] = field(default_factory=dict)
    
    # Statistical tracking and cache stats
    optimal_K_histogram: Dict[int, int] = field(default_factory=dict)
    cache_stats: List[Dict] = field(default_factory=list)


class RegimeOptimizationExperiment(EnhancedOptimizationLandscapeExperiment):
    """
    Extends the EnhancedOptimizationLandscapeExperiment to perform
    multi-regime parameter studies with extended K-ranges and statistical rigor.
    """
    
    # Define the 4 parameter regimes exactly as in run_theorem_verification.py
    REGIME_CONFIGS = {
        "Slow Reversion, Low Volatility": {
            'theta_eigenvalue_range': [0.05, 0.2],
            'mu_range': [-1, 1],
            'sigma_diag_range': [0.1, 0.3],
            'sigma_corr_level': [0.0, 1.0]
        },
        "Fast Reversion, Low Volatility": {
            'theta_eigenvalue_range': [1.0, 3.0],
            'mu_range': [-1, 1],
            'sigma_diag_range': [0.1, 0.3],
            'sigma_corr_level': [0.0, 1.0]
        },
        "Slow Reversion, High Volatility": {
            'theta_eigenvalue_range': [0.05, 0.2],
            'mu_range': [-1, 1],
            'sigma_diag_range': [1.0, 2.0],
            'sigma_corr_level': [0.0, 1.0]
        },
        "Fast Reversion, High Volatility": {
            'theta_eigenvalue_range': [1.0, 3.0],
            'mu_range': [-1, 1],
            'sigma_diag_range': [1.0, 2.0],
            'sigma_corr_level': [0.0, 1.0]
        }
    }
    
    def __init__(self, regime_name: str, regime_config: Optional[Dict] = None, 
                 n_monte_carlo: int = 10, device=None, config: ExperimentConfig = None):
        """
        Initialize regime-specific experiment.
        
        Args:
            regime_name: Name of the parameter regime
            regime_config: Optional custom regime configuration
            n_monte_carlo: Number of Monte Carlo runs (default 10)
            device: Computing device (cuda/cpu)
            config: Centralized experiment configuration for parameters
        """
        super().__init__(device=device, config=config)
        
        self.regime_name = regime_name
        self.regime_config = regime_config or self.REGIME_CONFIGS.get(regime_name)
        if not self.regime_config:
            raise ValueError(f"Unknown regime: {regime_name}")
        
        # Update Monte Carlo runs
        self.n_monte_carlo = n_monte_carlo
        
        # ARCHITECTURAL REDESIGN: Enhancement Cascade K-ranges
        # Phase 0: Analytical OU Solution (find K* + provide initialization)
        self.analytical_ou_K_values = [1, 2, 4, 8, 16, 32, 64, 128, 256]  # Extended range to find optimal K*
        # Phase 2: Signature Methods (use optimal initialization from Analytical OU)
        self.signature_K_values = [16, 64, 256, 1024, 4096]  # Keep existing signature range
        # Phase 3: Method of Moments (full coverage baseline)
        self.method_of_moments_K_values = [1, 2, 4, 8, 16, 64, 256, 1024, 4096]  # Complete coverage
        
        # Combined list for plotting
        self.all_K_values = sorted(set(self.analytical_ou_K_values + self.signature_K_values + self.method_of_moments_K_values))
        
        logger.info(f"Initialized RegimeOptimizationExperiment for '{regime_name}'")
        logger.info(f"Regime config: {self.regime_config}")
        logger.info(f"Phase 0 Analytical OU K values: {self.analytical_ou_K_values}")
        logger.info(f"Phase 2 Signature K values: {self.signature_K_values}")
        logger.info(f"Phase 3 Method of Moments K values: {self.method_of_moments_K_values}")
        logger.info(f"Monte Carlo runs: {self.n_monte_carlo}")
    
    def generate_true_parameters(self, seed: int = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Generate true parameters using the regime configuration.
        
        Args:
            seed: Random seed for reproducibility
            
        Returns:
            Tuple of (theta, mu, sigma) tensors
        """
        if seed is not None:
            torch.manual_seed(seed)
            np.random.seed(seed)
        
        # Use the exact parameter generation from numerical/parameters.py
        theta, mu, sigma = generate_ou_parameters_for_regime(
            self.d, self.device, self.regime_config, 1
        )
        
        # Remove batch dimension
        theta = theta.squeeze(0)
        mu = mu.squeeze(0)
        sigma = sigma.squeeze(0)
        
        return theta, mu, sigma
    
    def run_single_regime_simulation(self, mc_index: int) -> Dict:
        """
        Run a single Monte Carlo simulation using the proper 3-phase hierarchical architecture.
        
        Args:
            mc_index: Index of the current simulation
            
        Returns:
            Dictionary of results including optimal K selection and all phases
        """
        logger.info(f"  Monte Carlo run {mc_index + 1}/{self.n_monte_carlo} for {self.regime_name}")
        
        # Set random seed for reproducibility
        torch.manual_seed(42 + mc_index)
        np.random.seed(42 + mc_index)
        
        # Generate parameters using regime configuration
        theta, mu, sigma = generate_ou_parameters_for_regime(
            self.d, self.device, self.regime_config, 1
        )
        theta = theta.squeeze(0)
        mu = mu.squeeze(0)
        sigma = sigma.squeeze(0)
        
        # Generate path
        paths = generate_ou_process(
            1, self.n_steps, self.T, self.d,
            theta.unsqueeze(0), mu.unsqueeze(0), sigma.unsqueeze(0),
            self.device, use_time_augmentation=False
        )
        path = paths[0]
        
        # ==================== PHASE 0: Classical Benchmarks ====================
        classical_results = {
            'analytical_ou': {},
            'method_of_moments': {}
        }
        
        # Test Analytical OU across K values
        for K in self.analytical_ou_K_values:
            if self.n_steps % K != 0:
                continue
            
            start_time = time.time()
            
            result = self.analytical_ou_calibrator.estimate(
                path, K, self.T,
                params=self.analytical_ou_params,  # Not used but required for interface
                verbose=False
            )
            
            mse = compute_parameter_mse(
                (theta, mu, sigma),
                (result.theta, result.mu, result.sigma)
            )
            
            elapsed = time.time() - start_time
            classical_results['analytical_ou'][K] = {
                'mse': mse,
                'converged': result.converged,
                'convergence_rate': getattr(result, 'convergence_rate', 100.0),
                'time': elapsed
            }
        
        # Test Method of Moments across K values
        for K in self.method_of_moments_K_values:
            if self.n_steps % K != 0:
                continue
            
            start_time = time.time()
            
            result = self.moments_calibrator.estimate(
                path, K, self.T,
                params=self.analytical_ou_params,  # Not used but required for interface
                verbose=False
            )
            
            mse = compute_parameter_mse(
                (theta, mu, sigma),
                (result.theta, result.mu, result.sigma)
            )
            
            elapsed = time.time() - start_time
            classical_results['method_of_moments'][K] = {
                'mse': mse,
                'converged': result.converged,
                'convergence_rate': getattr(result, 'convergence_rate', 100.0),
                'time': elapsed
            }
        
        # ==================== PHASE 0 POST-PROCESSING: K* Selection ====================
        logger.info(f"    PHASE 0: K* Selection from Analytical OU results")
        
        # Find K* (optimal K from Analytical OU phase)
        best_analytical_mse = float('inf')
        K_star = None
        optimal_init_params = None
        
        for K in self.analytical_ou_K_values:
            if K in classical_results['analytical_ou']:
                mse = classical_results['analytical_ou'][K]['mse']
                if mse < best_analytical_mse:
                    best_analytical_mse = mse
                    K_star = K
                    # Get analytical OU parameters as smart initialization
                    result = self.analytical_ou_calibrator.estimate(
                        path, K, self.T,
                        params=self.analytical_ou_params,  # Not used - closed form
                        verbose=False
                    )
                    optimal_init_params = (
                        result.theta.clone().float(),
                        result.mu.clone().float(),
                        result.sigma.clone().float()
                    )
        
        if K_star is None:
            # Fallback to first valid K if no analytical results
            for K in self.analytical_ou_K_values:
                if self.n_steps % K == 0:
                    K_star = K
                    optimal_init_params = None
                    break
            
        logger.info(f"    Selected K* = {K_star} (MSE = {best_analytical_mse:.6f})")
        
        # ==================== PHASE 1: Enhanced MLE with Smart Initialization ====================
        logger.info(f"    PHASE 1: Enhanced MLE with K*={K_star} and smart initialization")
        start_time = time.time()
        
        # Enhanced MLE with smart initialization from Analytical OU K*
        # Convert initialization parameters to double precision to match MLE expectations
        if optimal_init_params is not None:
            smart_init_params = (
                optimal_init_params[0].double(),
                optimal_init_params[1].double(),
                optimal_init_params[2].double()
            )
        else:
            smart_init_params = None
            
        # Use enhanced_mle_params for consistency between logging and actual usage
        fine_tuning_params = self.enhanced_mle_params
        
        enhanced_result = self.mle_calibrator.estimate(
            path, K_star, self.T,
            params=fine_tuning_params,   # Use fine-tuning params when smart-initialized
            init_params=smart_init_params,  # Smart initialization with correct types
            verbose=False
        )
        
        raw_enhanced_mse = compute_parameter_mse(
            (theta, mu, sigma),
            (enhanced_result.theta, enhanced_result.mu, enhanced_result.sigma)
        )
        
        # Enhancement logic: only accept improvements over analytical OU baseline
        # True enhancers should never be worse than the baseline
        enhanced_mse = min(raw_enhanced_mse, best_analytical_mse)
        is_enhancement = raw_enhanced_mse < best_analytical_mse
        
        enhanced_time = time.time() - start_time
        
        logger.info(f"      Enhanced MLE: Raw MSE={raw_enhanced_mse:.6f}, Baseline MSE={best_analytical_mse:.6f}, Final MSE={enhanced_mse:.6f}, Enhanced={is_enhancement}")
        
        # Store enhanced MLE results
        enhanced_mle_data = {
            'K': K_star,
            'mse': enhanced_mse,
            'raw_mse': raw_enhanced_mse,  # Store the raw MSE for analysis
            'is_enhancement': is_enhancement,  # Track if this was actually an enhancement
            'theta': enhanced_result.theta.clone(),
            'mu': enhanced_result.mu.clone(),
            'sigma': enhanced_result.sigma.clone(),
            'converged': enhanced_result.converged,
            'time': enhanced_time
        }
        
        # ==================== PHASE 2: Signature Methods with Smart Initialization ====================
        logger.info(f"    PHASE 2: Signature Methods with smart initialization")
        # Use smart initialization from Analytical OU K*
        warm_start_params = optimal_init_params
        
        signature_results = {
            'K': [],
            'Expected': [], 'Expected_time': [], 'Expected_converged': [], 'Expected_raw_mse': [], 'Expected_is_enhancement': [],
            'Rescaled': [], 'Rescaled_time': [], 'Rescaled_converged': [], 'Rescaled_raw_mse': [], 'Rescaled_is_enhancement': []
        }
        
        for K in self.signature_K_values:
            if self.n_steps % K != 0:
                continue
            
            signature_results['K'].append(K)
            
            # Expected Signature with warm-start
            exp_start = time.time()
            try:
                theta_exp, mu_exp, sigma_exp, exp_conv = self.expected_sig_calibrator.estimate(
                    path, K, self.T,
                    params=self.signature_params,
                    init_params=warm_start_params,  # Warm-start from Phase 1
                    verbose=False
                )
                raw_exp_mse = compute_parameter_mse((theta, mu, sigma), (theta_exp, mu_exp, sigma_exp))
                # Enhancement logic: only accept improvements over analytical OU baseline
                exp_mse = min(raw_exp_mse, best_analytical_mse)
                is_exp_enhancement = raw_exp_mse < best_analytical_mse
                exp_time = time.time() - exp_start
                
                logger.info(f"        Expected Sig K={K}: Raw MSE={raw_exp_mse:.6f}, Baseline={best_analytical_mse:.6f}, Final MSE={exp_mse:.6f}, Enhanced={is_exp_enhancement}")
                
                signature_results['Expected'].append(exp_mse)
                signature_results['Expected_time'].append(exp_time)
                signature_results['Expected_converged'].append(exp_conv)
                signature_results['Expected_raw_mse'].append(raw_exp_mse)  # Store raw MSE for analysis
                signature_results['Expected_is_enhancement'].append(is_exp_enhancement)
            except Exception as e:
                exp_time = time.time() - exp_start
                signature_results['Expected'].append(np.nan)
                signature_results['Expected_time'].append(exp_time)
                signature_results['Expected_converged'].append(0.0)
                signature_results['Expected_raw_mse'].append(np.nan)
                signature_results['Expected_is_enhancement'].append(False)
            
            # Rescaled Signature with warm-start
            rsc_start = time.time()
            try:
                theta_rsc, mu_rsc, sigma_rsc, rsc_conv = self.rescaled_sig_calibrator.estimate(
                    path, K, self.T,
                    params=self.signature_params,
                    init_params=warm_start_params,  # Warm-start from Phase 1
                    verbose=False
                )
                raw_rsc_mse = compute_parameter_mse((theta, mu, sigma), (theta_rsc, mu_rsc, sigma_rsc))
                # Enhancement logic: only accept improvements over analytical OU baseline
                rsc_mse = min(raw_rsc_mse, best_analytical_mse)
                is_rsc_enhancement = raw_rsc_mse < best_analytical_mse
                rsc_time = time.time() - rsc_start
                
                logger.info(f"        Rescaled Sig K={K}: Raw MSE={raw_rsc_mse:.6f}, Baseline={best_analytical_mse:.6f}, Final MSE={rsc_mse:.6f}, Enhanced={is_rsc_enhancement}")
                
                signature_results['Rescaled'].append(rsc_mse)
                signature_results['Rescaled_time'].append(rsc_time)
                signature_results['Rescaled_converged'].append(rsc_conv)
                signature_results['Rescaled_raw_mse'].append(raw_rsc_mse)  # Store raw MSE for analysis  
                signature_results['Rescaled_is_enhancement'].append(is_rsc_enhancement)
            except Exception as e:
                rsc_time = time.time() - rsc_start
                signature_results['Rescaled'].append(np.nan)
                signature_results['Rescaled_time'].append(rsc_time)
                signature_results['Rescaled_converged'].append(0.0)
                signature_results['Rescaled_raw_mse'].append(np.nan)
                signature_results['Rescaled_is_enhancement'].append(False)
        
        return {
            'optimal_K': K_star,
            'optimal_init_params': optimal_init_params,
            'classical_results': classical_results,  # Phase 0: Analytical OU + Method of Moments
            'enhanced_mle': enhanced_mle_data,  # Phase 1: Enhanced MLE with smart init
            'signature_results': signature_results  # Phase 2: Signature Methods with smart init
        }
    
    def run_regime_experiment(self, use_parallel: bool = True, max_workers: Optional[int] = None, save_dir: str = 'plots/regime_studies') -> RegimeResults:
        """
        Run the complete regime experiment with all Monte Carlo simulations.
        
        Args:
            use_parallel: Whether to use parallel execution (default: True)
            max_workers: Number of parallel workers (default: min(8, n_monte_carlo))
            save_dir: Directory to save plots and results (default: 'plots/regime_studies')
        
        Returns:
            RegimeResults object with all collected data
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"STARTING REGIME EXPERIMENT: {self.regime_name}")
        if use_parallel:
            logger.info(f"PARALLEL EXECUTION ENABLED - Workers: {max_workers or min(8, self.n_monte_carlo)}")
        logger.info(f"{'='*80}")
        
        regime_results = RegimeResults(regime_name=self.regime_name)
        optimal_K_histogram = {K: 0 for K in self.analytical_ou_K_values}
        
        # Initialize result dictionaries for all K values
        for K in self.analytical_ou_K_values:
            regime_results.analytical_ou_mse[K] = []
            regime_results.analytical_ou_convergence[K] = []
            regime_results.analytical_ou_time[K] = []
            
        for K in self.method_of_moments_K_values:
            regime_results.method_of_moments_mse[K] = []
            regime_results.method_of_moments_convergence[K] = []
            regime_results.method_of_moments_time[K] = []
            
        for K in self.signature_K_values:
            regime_results.expected_sig_mse[K] = []
            regime_results.expected_sig_convergence[K] = []
            regime_results.expected_sig_time[K] = []
            regime_results.rescaled_sig_mse[K] = []
            regime_results.rescaled_sig_convergence[K] = []
            regime_results.rescaled_sig_time[K] = []
        
        # Choose execution method
        if use_parallel and self.n_monte_carlo > 1:
            mc_results_list = self._run_parallel_monte_carlo(max_workers)
        else:
            # Sequential execution (fallback or single MC run)
            mc_results_list = []
            for mc_index in range(self.n_monte_carlo):
                mc_results = self.run_single_regime_simulation(mc_index)
                mc_results_list.append((mc_index, mc_results))
        
        # Process results (same for both parallel and sequential)
        for mc_index, mc_results in mc_results_list:
            # Update optimal K histogram and track K* selections
            optimal_K_histogram[mc_results['optimal_K']] += 1
            regime_results.optimal_k_star.append(mc_results['optimal_K'])
            regime_results.analytical_ou_optimal_params.append(mc_results['optimal_init_params'])
            
            # Collect Classical results (Phase 0) - Analytical OU and Method of Moments
            if 'classical_results' in mc_results:
                for K, res in mc_results['classical_results']['analytical_ou'].items():
                    if K not in regime_results.analytical_ou_mse:
                        regime_results.analytical_ou_mse[K] = []
                        regime_results.analytical_ou_convergence[K] = []
                        regime_results.analytical_ou_time[K] = []
                    regime_results.analytical_ou_mse[K].append(res['mse'])
                    regime_results.analytical_ou_convergence[K].append(res['convergence_rate'])
                    regime_results.analytical_ou_time[K].append(res['time'])
                
                for K, res in mc_results['classical_results']['method_of_moments'].items():
                    if K not in regime_results.method_of_moments_mse:
                        regime_results.method_of_moments_mse[K] = []
                        regime_results.method_of_moments_convergence[K] = []
                        regime_results.method_of_moments_time[K] = []
                    regime_results.method_of_moments_mse[K].append(res['mse'])
                    regime_results.method_of_moments_convergence[K].append(res['convergence_rate'])
                    regime_results.method_of_moments_time[K].append(res['time'])
            
            # Collect Enhanced MLE results (Phase 1)
            enhanced = mc_results['enhanced_mle']
            regime_results.enhanced_mle_mse.append(enhanced['mse'])
            regime_results.enhanced_mle_K.append(enhanced['K'])
            regime_results.enhanced_mle_convergence.append(enhanced['converged'])
            regime_results.enhanced_mle_time.append(enhanced['time'])
            regime_results.enhanced_mle_enhancement_rate.append(enhanced.get('is_enhancement', False))
            
            # Collect Signature results (Phase 2)
            sig_results = mc_results['signature_results']
            for i, K in enumerate(sig_results['K']):
                # Initialize K-specific lists if not present
                if K not in regime_results.expected_sig_enhancement_rate:
                    regime_results.expected_sig_enhancement_rate[K] = []
                    regime_results.rescaled_sig_enhancement_rate[K] = []
                
                regime_results.expected_sig_mse[K].append(sig_results['Expected'][i])
                regime_results.expected_sig_convergence[K].append(sig_results['Expected_converged'][i])
                regime_results.expected_sig_time[K].append(sig_results['Expected_time'][i])
                regime_results.expected_sig_enhancement_rate[K].append(sig_results.get('Expected_is_enhancement', [False] * len(sig_results['K']))[i])
                
                regime_results.rescaled_sig_mse[K].append(sig_results['Rescaled'][i])
                regime_results.rescaled_sig_convergence[K].append(sig_results['Rescaled_converged'][i])
                regime_results.rescaled_sig_time[K].append(sig_results['Rescaled_time'][i])
                regime_results.rescaled_sig_enhancement_rate[K].append(sig_results.get('Rescaled_is_enhancement', [False] * len(sig_results['K']))[i])
            
            # Collect cache statistics if available
            if OPTIMIZATIONS_AVAILABLE:
                cache_stats = get_cache_stats()
                regime_results.cache_stats.append(cache_stats)
        
        # Store optimal K histogram
        regime_results.optimal_K_histogram = optimal_K_histogram
        
        # Log summary statistics
        self._log_regime_summary(regime_results, save_dir)
        
        # Log runtime and enhancement statistics
        self._log_runtime_and_enhancement_stats(regime_results)
        
        # Automatically generate plots and save results
        logger.info("\nGenerating plots and saving results...")
        self.plot_regime_landscape(regime_results, save_dir)
        detailed_results_dir = os.path.join(save_dir, 'detailed_results')
        self.save_regime_results(regime_results, detailed_results_dir)
        logger.info(f"Plots and results saved to {save_dir}/")
        
        return regime_results
    
    def _log_runtime_and_enhancement_stats(self, results: RegimeResults):
        """Log detailed runtime and enhancement statistics for each method and K value."""
        logger.info(f"\nðŸ“Š RUNTIME & ENHANCEMENT STATISTICS for {self.regime_name}:")
        logger.info("=" * 80)
        
        # Enhanced MLE statistics (single K* per MC run)
        if results.enhanced_mle_time and results.enhanced_mle_enhancement_rate:
            avg_runtime = np.mean(results.enhanced_mle_time)
            enhancement_rate = np.mean(results.enhanced_mle_enhancement_rate) * 100
            consensus_k = max(set(results.enhanced_mle_K), key=results.enhanced_mle_K.count) if results.enhanced_mle_K else "Unknown"
            
            logger.info(f"ðŸ”§ Enhanced MLE (K*={consensus_k}):")
            logger.info(f"   â±ï¸  Average Runtime: {avg_runtime:.2f} seconds")
            logger.info(f"   âœ¨ Enhancement Rate: {enhancement_rate:.1f}% ({sum(results.enhanced_mle_enhancement_rate)}/{len(results.enhanced_mle_enhancement_rate)} runs)")
        
        # Expected Signature statistics by K value
        if results.expected_sig_time:
            logger.info(f"\nðŸŽ¯ Expected Signature Method:")
            for K in sorted(results.expected_sig_time.keys()):
                if results.expected_sig_time[K] and results.expected_sig_enhancement_rate.get(K):
                    avg_runtime = np.mean(results.expected_sig_time[K])
                    enhancement_rate = np.mean(results.expected_sig_enhancement_rate[K]) * 100
                    total_runs = len(results.expected_sig_enhancement_rate[K])
                    enhanced_runs = sum(results.expected_sig_enhancement_rate[K])
                    
                    logger.info(f"   K={K:4d}: â±ï¸ {avg_runtime:6.2f}s | âœ¨ {enhancement_rate:5.1f}% ({enhanced_runs}/{total_runs})")
        
        # Rescaled Signature statistics by K value  
        if results.rescaled_sig_time:
            logger.info(f"\nðŸŽ¯ Rescaled Signature Method:")
            for K in sorted(results.rescaled_sig_time.keys()):
                if results.rescaled_sig_time[K] and results.rescaled_sig_enhancement_rate.get(K):
                    avg_runtime = np.mean(results.rescaled_sig_time[K])
                    enhancement_rate = np.mean(results.rescaled_sig_enhancement_rate[K]) * 100
                    total_runs = len(results.rescaled_sig_enhancement_rate[K])
                    enhanced_runs = sum(results.rescaled_sig_enhancement_rate[K])
                    
                    logger.info(f"   K={K:4d}: â±ï¸ {avg_runtime:6.2f}s | âœ¨ {enhancement_rate:5.1f}% ({enhanced_runs}/{total_runs})")
        
        # Summary efficiency metrics
        logger.info(f"\nðŸ“ˆ EFFICIENCY SUMMARY:")
        total_enhanced_mle_time = sum(results.enhanced_mle_time) if results.enhanced_mle_time else 0
        total_expected_time = sum([sum(times) for times in results.expected_sig_time.values()])
        total_rescaled_time = sum([sum(times) for times in results.rescaled_sig_time.values()])
        
        logger.info(f"   Enhanced MLE Total Time: {total_enhanced_mle_time:.1f}s")
        logger.info(f"   Expected Sig Total Time: {total_expected_time:.1f}s")
        logger.info(f"   Rescaled Sig Total Time: {total_rescaled_time:.1f}s")
        logger.info("=" * 80)
    
    def _run_parallel_monte_carlo(self, max_workers: Optional[int] = None) -> List[Tuple[int, Dict]]:
        """
        Run Monte Carlo simulations in parallel using ThreadPoolExecutor.
        
        Args:
            max_workers: Number of parallel workers (default: min(8, n_monte_carlo))
            
        Returns:
            List of (mc_index, results) tuples, sorted by mc_index
        """
        # Determine optimal number of workers
        if max_workers is None:
            max_workers = min(8, self.n_monte_carlo)  # Cap at 8 for diminishing returns
        
        results = []
        completed_count = 0
        lock = threading.Lock()
        
        def log_progress():
            nonlocal completed_count
            with lock:
                completed_count += 1
                if completed_count % max(1, self.n_monte_carlo // 10) == 0:
                    logger.info(f"  Progress: {completed_count}/{self.n_monte_carlo} MC runs completed")
        
        try:
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Submit all MC runs
                future_to_mc = {
                    executor.submit(self.run_single_regime_simulation, mc_index): mc_index
                    for mc_index in range(self.n_monte_carlo)
                }
                
                # Collect results as they complete
                for future in as_completed(future_to_mc):
                    mc_index = future_to_mc[future]
                    try:
                        mc_results = future.result()
                        results.append((mc_index, mc_results))
                        log_progress()
                    except Exception as e:
                        logger.error(f"MC run {mc_index} failed: {e}")
                        # Fallback to sequential for this run
                        logger.info(f"Retrying MC run {mc_index} sequentially...")
                        mc_results = self.run_single_regime_simulation(mc_index)
                        results.append((mc_index, mc_results))
                        log_progress()
                
                # Sort results by mc_index to ensure reproducibility
                results.sort(key=lambda x: x[0])
                
        except Exception as e:
            logger.error(f"Parallel execution failed: {e}")
            logger.info("Falling back to sequential execution...")
            # Fallback to sequential
            results = []
            for mc_index in range(self.n_monte_carlo):
                mc_results = self.run_single_regime_simulation(mc_index)
                results.append((mc_index, mc_results))
        
        return results
    
    def _compute_regime_statistics(self, results: RegimeResults):
        """
        Compute ALL regime statistics once and cache for reuse.
        This eliminates redundant calculations across plotting, logging, and CSV functions.
        """
        if hasattr(results, '_cached_stats'):
            return results._cached_stats
        
        stats = {}
        
        # Enhanced MLE statistics 
        if results.optimal_K_histogram and results.enhanced_mle_mse:
            consensus_k = max(results.optimal_K_histogram, key=results.optimal_K_histogram.get)
            consensus_count = results.optimal_K_histogram[consensus_k]
            
            stats['enhanced_mle'] = {
                'consensus_k': consensus_k,
                'consensus_count': consensus_count,
                'all_mse': results.enhanced_mle_mse,
                'all_convergence': results.enhanced_mle_convergence,
                'all_time': results.enhanced_mle_time,
                'mean_mse': np.mean(results.enhanced_mle_mse),
                'std_mse': np.std(results.enhanced_mle_mse) if len(results.enhanced_mle_mse) > 1 else 0,
                'mean_convergence': np.mean(results.enhanced_mle_convergence) * 100
            }
        
        # Best signature method statistics (compute once, reuse everywhere)
        best_expected = {'mse': float('inf'), 'k': None}
        best_rescaled = {'mse': float('inf'), 'k': None}
        
        for K in self.signature_K_values:
            # Expected signature
            if results.expected_sig_mse[K]:
                valid_mses = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_expected['mse']:
                        best_expected.update({'mse': mean_mse, 'k': K})
            
            # Rescaled signature  
            if results.rescaled_sig_mse[K]:
                valid_mses = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_rescaled['mse']:
                        best_rescaled.update({'mse': mean_mse, 'k': K})
        
        stats['best_expected'] = best_expected
        stats['best_rescaled'] = best_rescaled
        
        # Improvement calculations
        if 'enhanced_mle' in stats:
            enhanced_baseline = stats['enhanced_mle']['mean_mse']
            stats['improvements'] = {
                'expected_pct': (1 - best_expected['mse'] / enhanced_baseline) * 100 if not np.isinf(best_expected['mse']) else 0,
                'rescaled_pct': (1 - best_rescaled['mse'] / enhanced_baseline) * 100 if not np.isinf(best_rescaled['mse']) else 0
            }
        
        # Cache the results to avoid recalculation
        results._cached_stats = stats
        return stats

    def _get_enhanced_mle_statistics(self, results: RegimeResults):
        """Legacy interface for Enhanced MLE statistics (now uses cached computation)."""
        stats = self._compute_regime_statistics(results)
        if 'enhanced_mle' in stats:
            mle_stats = stats['enhanced_mle']
            logger.info(f"  Enhanced MLE consensus K: {mle_stats['consensus_k']} (selected {mle_stats['consensus_count']}/{self.n_monte_carlo} times)")
            logger.info(f"  Using ALL {len(mle_stats['all_mse'])} Enhanced MLE results for statistics")
            logger.info(f"  Plotting location: K={mle_stats['consensus_k']} (design choice for visualization)")
            return mle_stats['all_mse'], mle_stats['all_convergence'], mle_stats['all_time'], mle_stats['consensus_k']
        return [], [], [], None

    def _log_regime_summary(self, results: RegimeResults, save_dir: str = 'plots/regime_studies'):
        """Log summary statistics for the regime using cached computations."""
        logger.info(f"\nSummary for {self.regime_name}:")
        
        # Get cached statistics (computed once, reused everywhere)
        stats = self._compute_regime_statistics(results)
        
        # Phase 0: Best Analytical OU K*
        best_analytical_k = None
        best_analytical_mse = float('inf')
        # No longer needed - Phase 1 is now Enhanced MLE using K*
        # Analytical OU uses closed-form solution
        
        # Phase 2: Enhanced MLE performance (from cached stats)
        if 'enhanced_mle' in stats:
            mle_stats = stats['enhanced_mle']
            enhanced_mle_mean_mse = mle_stats['mean_mse']
            enhanced_mle_convergence = mle_stats['mean_convergence']
            consensus_k = mle_stats['consensus_k']
        else:
            enhanced_mle_mean_mse = float('inf')
            enhanced_mle_convergence = 0
            consensus_k = None
        
        # Phase 3: Best signature methods (from cached stats)
        best_exp_k = stats['best_expected']['k']
        best_exp_mse = stats['best_expected']['mse']
        best_rsc_k = stats['best_rescaled']['k'] 
        best_rsc_mse = stats['best_rescaled']['mse']
        
        # Log results
        logger.info(f"  Phase 0 - Best Analytical OU: K={best_analytical_k}, MSE={best_analytical_mse:.4f}")
        logger.info(f"  Phase 1 - Enhanced MLE (all results, plot at K={consensus_k}): MSE={enhanced_mle_mean_mse:.4f}, Convergence={enhanced_mle_convergence:.1f}%")
        logger.info(f"  Phase 2 - Best Expected Sig: K={best_exp_k}, MSE={best_exp_mse:.4f}")
        logger.info(f"  Phase 2 - Best Rescaled Sig: K={best_rsc_k}, MSE={best_rsc_mse:.4f}")
        
        # Calculate improvements vs Enhanced MLE (from cached stats)
        if 'improvements' in stats:
            exp_improvement = stats['improvements']['expected_pct']
            rsc_improvement = stats['improvements']['rescaled_pct']
            logger.info(f"  Expected Sig improvement over Enhanced MLE (all results): {exp_improvement:.1f}%")
            logger.info(f"  Rescaled Sig improvement over Enhanced MLE (all results): {rsc_improvement:.1f}%")
        
        # Optimal K histogram
        logger.info(f"  Optimal K distribution: {results.optimal_K_histogram}")
        
        # Perform and log hypothesis testing
        hypothesis_results = self.perform_regime_hypothesis_testing(results)
        self._log_hypothesis_results(hypothesis_results)
        
        # Save hypothesis testing results to CSV
        detailed_results_dir = os.path.join(save_dir, 'detailed_results')
        self._save_hypothesis_results_to_csv(hypothesis_results, detailed_results_dir)
    
    def perform_regime_hypothesis_testing(self, results: RegimeResults):
        """
        Perform hypothesis testing comparing signature methods vs Enhanced MLE.
        Tests both individual regime and method-specific comparisons.
        
        Returns:
            Dict containing hypothesis testing results
        """
        from scipy import stats
        
        hypothesis_results = {
            'regime_name': self.regime_name,
            'tests': {}
        }
        
        # Get Enhanced MLE data (all results for maximum statistical power)
        enhanced_mle_data = results.enhanced_mle_mse
        
        if not enhanced_mle_data or len(enhanced_mle_data) < 2:
            logger.warning("Insufficient Enhanced MLE data for hypothesis testing")
            return hypothesis_results
        
        # Test Expected Signature methods at each K
        for K in self.signature_K_values:
            if results.expected_sig_mse[K]:
                sig_data = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                
                if len(sig_data) >= 2 and len(sig_data) == len(enhanced_mle_data):
                    # Paired t-test (same Monte Carlo runs)
                    t_stat, p_value = stats.ttest_rel(sig_data, enhanced_mle_data)
                    
                    hypothesis_results['tests'][f'Expected_K{K}'] = {
                        'method': 'Expected Signature',
                        'K': K,
                        'test_type': 'paired_t_test',
                        't_statistic': t_stat,
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'improvement_direction': 'signature_better' if t_stat < 0 else 'mle_better',
                        'mean_signature': np.mean(sig_data),
                        'mean_enhanced_mle': np.mean(enhanced_mle_data),
                        'improvement_pct': (1 - np.mean(sig_data) / np.mean(enhanced_mle_data)) * 100,
                        'sample_size': len(sig_data)
                    }
                elif len(sig_data) >= 2:
                    # Independent t-test (different sample sizes)
                    t_stat, p_value = stats.ttest_ind(sig_data, enhanced_mle_data)
                    
                    hypothesis_results['tests'][f'Expected_K{K}'] = {
                        'method': 'Expected Signature',
                        'K': K,
                        'test_type': 'independent_t_test',
                        't_statistic': t_stat,
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'improvement_direction': 'signature_better' if t_stat < 0 else 'mle_better',
                        'mean_signature': np.mean(sig_data),
                        'mean_enhanced_mle': np.mean(enhanced_mle_data),
                        'improvement_pct': (1 - np.mean(sig_data) / np.mean(enhanced_mle_data)) * 100,
                        'sample_size_sig': len(sig_data),
                        'sample_size_mle': len(enhanced_mle_data)
                    }
        
        # Test Rescaled Signature methods at each K
        for K in self.signature_K_values:
            if results.rescaled_sig_mse[K]:
                sig_data = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                
                if len(sig_data) >= 2 and len(sig_data) == len(enhanced_mle_data):
                    # Paired t-test (same Monte Carlo runs)
                    t_stat, p_value = stats.ttest_rel(sig_data, enhanced_mle_data)
                    
                    hypothesis_results['tests'][f'Rescaled_K{K}'] = {
                        'method': 'Rescaled Signature',
                        'K': K,
                        'test_type': 'paired_t_test',
                        't_statistic': t_stat,
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'improvement_direction': 'signature_better' if t_stat < 0 else 'mle_better',
                        'mean_signature': np.mean(sig_data),
                        'mean_enhanced_mle': np.mean(enhanced_mle_data),
                        'improvement_pct': (1 - np.mean(sig_data) / np.mean(enhanced_mle_data)) * 100,
                        'sample_size': len(sig_data)
                    }
                elif len(sig_data) >= 2:
                    # Independent t-test (different sample sizes)
                    t_stat, p_value = stats.ttest_ind(sig_data, enhanced_mle_data)
                    
                    hypothesis_results['tests'][f'Rescaled_K{K}'] = {
                        'method': 'Rescaled Signature',
                        'K': K,
                        'test_type': 'independent_t_test',
                        't_statistic': t_stat,
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'improvement_direction': 'signature_better' if t_stat < 0 else 'mle_better',
                        'mean_signature': np.mean(sig_data),
                        'mean_enhanced_mle': np.mean(enhanced_mle_data),
                        'improvement_pct': (1 - np.mean(sig_data) / np.mean(enhanced_mle_data)) * 100,
                        'sample_size_sig': len(sig_data),
                        'sample_size_mle': len(enhanced_mle_data)
                    }
        
        return hypothesis_results
    
    def _log_hypothesis_results(self, hypothesis_results):
        """Log hypothesis testing results in a clear, academic format."""
        if not hypothesis_results['tests']:
            logger.info("  No hypothesis tests performed (insufficient data)")
            return
        
        logger.info(f"\n  HYPOTHESIS TESTING RESULTS vs Enhanced MLE:")
        logger.info(f"  {'='*60}")
        
        significant_results = []
        
        for test_name, result in hypothesis_results['tests'].items():
            method = result['method']
            K = result['K']
            p_val = result['p_value']
            significant = result['significant']
            improvement = result['improvement_pct']
            direction = result['improvement_direction']
            
            # Format significance
            sig_marker = "SIGNIFICANT" if significant else "Not significant"
            direction_marker = "Better" if direction == 'signature_better' else "Worse"
            
            logger.info(f"  {method} (K={K}): {sig_marker}")
            logger.info(f"    {direction_marker} - p-value: {p_val:.4f}, improvement: {improvement:+.1f}%")
            
            if significant and direction == 'signature_better':
                significant_results.append((method, K, improvement, p_val))
        
        # Summary of significant improvements
        if significant_results:
            logger.info(f"\n  SIGNIFICANT IMPROVEMENTS FOUND:")
            for method, K, improvement, p_val in significant_results:
                logger.info(f"    {method} (K={K}): {improvement:.1f}% better (p={p_val:.4f})")
        else:
            logger.info(f"\n  No statistically significant improvements found in this regime")
    
    def _save_hypothesis_results_to_csv(self, hypothesis_results, save_dir: str = 'plots/regime_studies/detailed_results'):
        """Save hypothesis testing results to CSV file."""
        os.makedirs(save_dir, exist_ok=True)
        
        if not hypothesis_results['tests']:
            logger.info(f"  No hypothesis testing data to save for {self.regime_name}")
            return
        
        # Create DataFrame for hypothesis testing results
        hypothesis_data = []
        
        for test_name, result in hypothesis_results['tests'].items():
            hypothesis_data.append({
                'regime': self.regime_name,
                'method': result['method'],
                'K': result['K'],
                'test_type': result['test_type'],
                't_statistic': result['t_statistic'],
                'p_value': result['p_value'],
                'significant': result['significant'],
                'improvement_direction': result['improvement_direction'],
                'mean_signature': result['mean_signature'],
                'mean_enhanced_mle': result['mean_enhanced_mle'],
                'improvement_pct': result['improvement_pct'],
                'sample_size': result.get('sample_size', result.get('sample_size_sig', 'N/A')),
                'sample_size_mle': result.get('sample_size_mle', 'N/A')
            })
        
        df = pd.DataFrame(hypothesis_data)
        
        # Save to CSV
        regime_filename = self.regime_name.lower().replace(' ', '_').replace(',', '')
        csv_path = os.path.join(save_dir, f'{regime_filename}_hypothesis_testing.csv')
        df.to_csv(csv_path, index=False)
        
        logger.info(f"  Saved hypothesis testing results to {csv_path}")
        
        return df
    
    def plot_regime_landscape(self, results: RegimeResults, save_dir: str = 'plots/regime_studies'):
        """
        Generate enhanced optimization landscape plot for the regime using 3-phase architecture.
        Creates 4 plots: 2 main plots (MSE & convergence), optimal K histogram, and improvement plot.
        
        Args:
            results: RegimeResults object
            save_dir: Directory to save plots
        """
        from scipy import stats  # Import here to avoid scoping issues
        os.makedirs(save_dir, exist_ok=True)
        
        # Create 2x2 subplot layout for 4 plots
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))
        
        # Prepare Phase 0: Classical method data
        analytical_ou_k_vals = []
        analytical_ou_mse_means = []
        analytical_ou_mse_stds = []
        
        for K in self.analytical_ou_K_values:
            if K in results.analytical_ou_mse and results.analytical_ou_mse[K]:
                analytical_ou_k_vals.append(K)
                analytical_ou_mse_means.append(np.mean(results.analytical_ou_mse[K]))
                analytical_ou_mse_stds.append(np.std(results.analytical_ou_mse[K]) if len(results.analytical_ou_mse[K]) > 1 else 0)
        
        mom_k_vals = []
        mom_mse_means = []
        mom_mse_stds = []
        
        for K in self.method_of_moments_K_values:
            if K in results.method_of_moments_mse and results.method_of_moments_mse[K]:
                mom_k_vals.append(K)
                mom_mse_means.append(np.mean(results.method_of_moments_mse[K]))
                mom_mse_stds.append(np.std(results.method_of_moments_mse[K]) if len(results.method_of_moments_mse[K]) > 1 else 0)
        
        # Prepare Phase 1: Quick MLE data
        # Quick MLE phase removed in Enhancement Cascade - skip this section
        quick_mle_k_vals = []
        quick_mle_mse_means = []
        quick_mle_mse_stds = []
        
        # Prepare Phase 3: Signature method data
        exp_k_vals = []
        exp_mse_means = []
        exp_mse_stds = []
        
        for K in self.signature_K_values:
            if results.expected_sig_mse[K]:
                valid_mses = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    exp_k_vals.append(K)
                    exp_mse_means.append(np.mean(valid_mses))
                    exp_mse_stds.append(np.std(valid_mses) if len(valid_mses) > 1 else 0)
        
        rsc_k_vals = []
        rsc_mse_means = []
        rsc_mse_stds = []
        
        for K in self.signature_K_values:
            if results.rescaled_sig_mse[K]:
                valid_mses = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    rsc_k_vals.append(K)
                    rsc_mse_means.append(np.mean(valid_mses))
                    rsc_mse_stds.append(np.std(valid_mses) if len(valid_mses) > 1 else 0)
        
        # Left panel: MSE vs K
        
        # Plot Phase 0: Classical methods (new baseline methods)
        if analytical_ou_k_vals:
            ax1.plot(analytical_ou_k_vals, analytical_ou_mse_means, 'D--', label='Analytical OU',
                    markersize=5, linewidth=1.5, color='#8B4513', alpha=0.8)
        
        if mom_k_vals:
            ax1.plot(mom_k_vals, mom_mse_means, 'p--', label='Method of Moments',
                    markersize=5, linewidth=1.5, color='#4B0082', alpha=0.8)
        
        # Plot Phase 1: Quick MLE curve (same color as Enhanced MLE) - NO CONFIDENCE INTERVALS
        if quick_mle_k_vals:
            # Always plot without error bars for Quick MLE
            ax1.plot(quick_mle_k_vals, quick_mle_mse_means, 's-', label='Quick MLE',
                    markersize=6, linewidth=2, color='#2E86AB', alpha=0.7)
        
        # Plot Phase 3: Signature methods
        if exp_k_vals:
            if self.n_monte_carlo > 1:
                ax1.errorbar(exp_k_vals, exp_mse_means, yerr=exp_mse_stds,
                           fmt='o-', label='Expected Signature', markersize=8,
                           linewidth=2, color='#A23B72', capsize=5)
            else:
                ax1.plot(exp_k_vals, exp_mse_means, 'o-', label='Expected Signature',
                        markersize=8, linewidth=2, color='#A23B72')
        
        if rsc_k_vals:
            if self.n_monte_carlo > 1:
                ax1.errorbar(rsc_k_vals, rsc_mse_means, yerr=rsc_mse_stds,
                           fmt='^-', label='Rescaled Signature', markersize=8,
                           linewidth=2, color='#F18F01', capsize=5)
            else:
                ax1.plot(rsc_k_vals, rsc_mse_means, '^-', label='Rescaled Signature',
                        markersize=8, linewidth=2, color='#F18F01')
        
        # Plot Phase 2: Enhanced MLE as single X mark at consensus K (design choice)
        all_mse, all_conv, all_time, consensus_k = self._get_enhanced_mle_statistics(results)
        
        if all_mse and consensus_k is not None:
            # Use ALL Enhanced MLE results for statistics (full statistical power)
            mean_mse = np.mean(all_mse)
            
            if len(all_mse) > 1:
                # Calculate 95% confidence interval from ALL results
                std_mse = np.std(all_mse)
                ci = stats.t.interval(0.95, len(all_mse)-1,
                                     loc=mean_mse,
                                     scale=std_mse/np.sqrt(len(all_mse)))
                ax1.errorbar(consensus_k, mean_mse, yerr=[[mean_mse - ci[0]], [ci[1] - mean_mse]],
                           fmt='X', markersize=12, color='#2E86AB', markeredgewidth=2,
                           capsize=5, label='Enhanced MLE')
            else:
                # Single sample: just plot the point
                ax1.plot(consensus_k, mean_mse, 'X', markersize=12, color='#2E86AB',
                       markeredgewidth=2, label='Enhanced MLE')
            
            logger.info(f"    Plotting Enhanced MLE: ALL {len(all_mse)} results, mean MSE={mean_mse:.4f}, plot at K={consensus_k}")
        
        ax1.set_xlabel('Number of Blocks (K)', fontsize=14)
        ax1.set_ylabel('Mean Squared Error', fontsize=14)
        ax1.set_xscale('log', base=2)
        ax1.set_yscale('log')
        ax1.set_title(f'4-Phase Hierarchical Calibration: {self.regime_name}', fontsize=16)
        
        # Add caption note about Enhanced MLE plotting choice
        ax1.text(0.02, 0.98, f'Enhanced MLE: All results used for statistics, plotted at consensus K={consensus_k}', 
                transform=ax1.transAxes, fontsize=8, va='top', ha='left', 
                bbox=dict(boxstyle='round,pad=0.3', facecolor='wheat', alpha=0.5))
        ax1.grid(True, alpha=0.3, linestyle='--', which='both')
        ax1.legend(fontsize=12, loc='best')
        
        # Right panel: Convergence rates
        # Classical methods (Phase 0)
        analytical_ou_conv_k = []
        analytical_ou_conv_rates = []
        
        for K in self.analytical_ou_K_values:
            if K in results.analytical_ou_convergence and results.analytical_ou_convergence[K]:
                analytical_ou_conv_k.append(K)
                analytical_ou_conv_rates.append(np.mean(results.analytical_ou_convergence[K]) * 100)
        
        mom_conv_k = []
        mom_conv_rates = []
        
        for K in self.method_of_moments_K_values:
            if K in results.method_of_moments_convergence and results.method_of_moments_convergence[K]:
                mom_conv_k.append(K)
                mom_conv_rates.append(np.mean(results.method_of_moments_convergence[K]) * 100)
        
        # Quick MLE phase removed in Enhancement Cascade - skip this section
        quick_mle_conv_k = []
        quick_mle_conv_rates = []
        
        exp_conv_k = []
        exp_conv_rates = []
        
        for K in self.signature_K_values:
            if results.expected_sig_convergence[K]:
                valid_conv = [x for x in results.expected_sig_convergence[K] if not np.isnan(x)]
                if valid_conv:
                    exp_conv_k.append(K)
                    exp_conv_rates.append(np.mean(valid_conv) * 100)
        
        rsc_conv_k = []
        rsc_conv_rates = []
        
        for K in self.signature_K_values:
            if results.rescaled_sig_convergence[K]:
                valid_conv = [x for x in results.rescaled_sig_convergence[K] if not np.isnan(x)]
                if valid_conv:
                    rsc_conv_k.append(K)
                    rsc_conv_rates.append(np.mean(valid_conv) * 100)
        
        # Plot convergence rates
        # Classical methods first (Phase 0)
        if analytical_ou_conv_k:
            ax2.plot(analytical_ou_conv_k, analytical_ou_conv_rates, 'D--', label='Analytical OU',
                    markersize=5, linewidth=1.5, color='#8B4513', alpha=0.8)
        
        if mom_conv_k:
            ax2.plot(mom_conv_k, mom_conv_rates, 'p--', label='Method of Moments',
                    markersize=5, linewidth=1.5, color='#4B0082', alpha=0.8)
        
        if quick_mle_conv_k:
            ax2.plot(quick_mle_conv_k, quick_mle_conv_rates, 's-', label='Quick MLE',
                    markersize=6, linewidth=2, color='#2E86AB', alpha=0.7)
        
        if exp_conv_k:
            ax2.plot(exp_conv_k, exp_conv_rates, 'o-', label='Expected Signature',
                    markersize=8, linewidth=2, color='#A23B72')
        
        if rsc_conv_k:
            ax2.plot(rsc_conv_k, rsc_conv_rates, '^-', label='Rescaled Signature',
                    markersize=8, linewidth=2, color='#F18F01')
        
        # Enhanced MLE convergence as single X mark at consensus K (using all results)
        if all_conv and consensus_k is not None:
            mean_conv = np.mean(all_conv) * 100
            ax2.plot(consensus_k, mean_conv, 'X', markersize=12, color='#2E86AB',
                   markeredgewidth=2, label='Enhanced MLE')
            logger.info(f"    Plotting Enhanced MLE convergence: ALL {len(all_conv)} results, mean={mean_conv:.1f}%, plot at K={consensus_k}")
        
        ax2.set_xlabel('Number of Blocks (K)', fontsize=14)
        ax2.set_ylabel('Convergence Rate [%]', fontsize=14)
        ax2.set_xscale('log', base=2)
        ax2.set_ylim(0, 105)
        ax2.set_title(f'Convergence Rates - {self.regime_name}', fontsize=16)
        ax2.grid(True, alpha=0.3, linestyle='--', which='both')
        ax2.legend(fontsize=12, loc='best')
        
        # ============ Plot 3: Optimal K Histogram (Phase 1) ============
        ax3.set_title(f'Optimal K Selection Histogram - {self.regime_name}', fontsize=14)
        
        if results.optimal_K_histogram:
            k_values = list(results.optimal_K_histogram.keys())
            counts = list(results.optimal_K_histogram.values())
            
            bars = ax3.bar(k_values, counts, color='#2E86AB', alpha=0.7, edgecolor='black')
            
            # Add count labels on bars
            for bar, count in zip(bars, counts):
                height = bar.get_height()
                if height > 0:
                    ax3.text(bar.get_x() + bar.get_width()/2., height,
                           f'{int(count)}', ha='center', va='bottom', fontsize=12)
            
            ax3.set_xlabel('Optimal K Value (Phase 1)', fontsize=12)
            ax3.set_ylabel('Frequency Count', fontsize=12)
            ax3.set_yscale('linear')
            ax3.grid(True, alpha=0.3, axis='y')
            
            # Set x-axis to show only actual K values
            ax3.set_xticks(k_values)
            ax3.set_xticklabels([str(k) for k in k_values])
        
        # ============ Plot 4: Relative Improvement over Enhanced MLE ============
        ax4.set_title(f'Signature Method Improvement vs Enhanced MLE (Consensus K) - {self.regime_name}', fontsize=14)
        
        # Use cached statistics for all calculations (major performance improvement)
        stats = self._compute_regime_statistics(results)
        
        # Calculate best results for each method from cached stats
        if 'enhanced_mle' in stats:
            enhanced_mle_mean_mse = stats['enhanced_mle']['mean_mse']
        else:
            enhanced_mle_mean_mse = float('inf')
        
        # Get best signature results from cached stats (no redundant calculations)
        best_exp_k = stats['best_expected']['k']
        best_rsc_k = stats['best_rescaled']['k']
        
        # Get improvements from cached stats (no redundant calculations) - SIGNATURE METHODS ONLY
        if 'enhanced_mle' in stats and 'improvements' in stats:
            exp_improvement = stats['improvements']['expected_pct']
            rsc_improvement = stats['improvements']['rescaled_pct']
            
            # Only show signature methods with their optimal K values
            methods = [f'Expected Signature\n(K={best_exp_k})', f'Rescaled Signature\n(K={best_rsc_k})']
            improvements = [exp_improvement, rsc_improvement]
            
            logger.info(f"    Fair comparison using ALL Enhanced MLE results: MSE={enhanced_mle_mean_mse:.4f}")
            logger.info(f"    Expected Sig improvement: {exp_improvement:+.1f}%, Rescaled Sig improvement: {rsc_improvement:+.1f}%")
        else:
            methods = ['Expected Signature\n(K=Unknown)', 'Rescaled Signature\n(K=Unknown)']
            improvements = [0, 0]
        
        # Color bars: green for positive improvement, red for negative
        colors = []
        for imp in improvements:
            if imp > 0:
                colors.append('#28A745')  # Green for improvement
            elif imp < 0:
                colors.append('#DC3545')  # Red for worse performance
            else:
                colors.append('#6C757D')  # Gray for no change
        
        bars = ax4.bar(methods, improvements, color=colors, alpha=0.7, edgecolor='black')
        
        # Add percentage labels on bars
        for bar, imp in zip(bars, improvements):
            height = bar.get_height()
            if height != 0:
                ax4.text(bar.get_x() + bar.get_width()/2., 
                        height + (0.5 if height > 0 else -2),
                        f'{imp:+.1f}%', ha='center', 
                        va='bottom' if height > 0 else 'top', 
                        fontsize=12, fontweight='bold')
        
        ax4.set_ylabel('Improvement over Enhanced MLE [%]', fontsize=12)
        ax4.grid(True, alpha=0.3, axis='y')
        ax4.axhline(y=0, color='black', linestyle='-', linewidth=1)
        
        # Set y-axis limits to show all data clearly
        max_abs = max(abs(min(improvements)), abs(max(improvements))) if improvements else 10
        ax4.set_ylim(-max_abs * 1.2, max_abs * 1.2)
        
        plt.suptitle(f'Enhanced Optimization Landscape Analysis: {self.regime_name}', 
                    fontsize=18, y=0.98)
        plt.tight_layout()
        
        # Save plot
        filename_base = self.regime_name.lower().replace(', ', '_').replace(' ', '_')
        plot_path = os.path.join(save_dir, f'{filename_base}_enhanced_landscape.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        logger.info(f"Saved regime plot to {plot_path}")
        
        plt.close()
    
    def save_regime_results(self, results: RegimeResults, save_dir: str = 'plots/regime_studies/detailed_results'):
        """
        Save detailed results to CSV following 3-phase architecture.
        
        Args:
            results: RegimeResults object
            save_dir: Directory to save CSV files
        """
        os.makedirs(save_dir, exist_ok=True)
        
        # Prepare data for CSV
        data_rows = []
        
        # Add Phase 0 Classical method results
        # Analytical OU
        for K in self.analytical_ou_K_values:
            row = {'K': K, 'Phase': 'Phase0_AnalyticalOU'}
            
            if K in results.analytical_ou_mse and results.analytical_ou_mse[K]:
                row['mean_MSE'] = np.mean(results.analytical_ou_mse[K])
                row['std_MSE'] = np.std(results.analytical_ou_mse[K])
                row['convergence_rate'] = np.mean(results.analytical_ou_convergence[K])
                row['mean_time'] = np.mean(results.analytical_ou_time[K])
            else:
                row['mean_MSE'] = np.nan
                row['std_MSE'] = np.nan
                row['convergence_rate'] = np.nan
                row['mean_time'] = np.nan
            
            data_rows.append(row)
        
        # Method of Moments
        for K in self.method_of_moments_K_values:
            row = {'K': K, 'Phase': 'Phase0_MethodOfMoments'}
            
            if K in results.method_of_moments_mse and results.method_of_moments_mse[K]:
                row['mean_MSE'] = np.mean(results.method_of_moments_mse[K])
                row['std_MSE'] = np.std(results.method_of_moments_mse[K])
                row['convergence_rate'] = np.mean(results.method_of_moments_convergence[K])
                row['mean_time'] = np.mean(results.method_of_moments_time[K])
            else:
                row['mean_MSE'] = np.nan
                row['std_MSE'] = np.nan
                row['convergence_rate'] = np.nan
                row['mean_time'] = np.nan
            
            data_rows.append(row)
        
        # Phase 1: Enhanced MLE with Smart Initialization (using K* from Phase 0)
        # Enhanced MLE results are stored per MC run, not per K, so we aggregate by consensus K
        if results.enhanced_mle_mse:
            consensus_k = max(set(results.enhanced_mle_K), key=results.enhanced_mle_K.count) if results.enhanced_mle_K else 'Unknown'
            row = {'K': consensus_k, 'Phase': 'Phase1_EnhancedMLE_SmartInit'}
            row['mean_MSE'] = np.mean(results.enhanced_mle_mse)
            row['std_MSE'] = np.std(results.enhanced_mle_mse) if len(results.enhanced_mle_mse) > 1 else 0
            row['convergence_rate'] = np.mean(results.enhanced_mle_convergence) * 100 if results.enhanced_mle_convergence else 0
            row['mean_time'] = np.mean(results.enhanced_mle_time) if results.enhanced_mle_time else 0
            data_rows.append(row)
        
        # Add Phase 2 Enhanced MLE results
        if results.enhanced_mle_mse:
            # Group by K value
            k_groups = {}
            for i, k in enumerate(results.enhanced_mle_K):
                if k not in k_groups:
                    k_groups[k] = []
                k_groups[k].append(i)
            
            for k, indices in k_groups.items():
                row = {'K': k, 'Phase': 'Phase2_EnhancedMLE'}
                k_mses = [results.enhanced_mle_mse[i] for i in indices]
                k_convs = [results.enhanced_mle_convergence[i] for i in indices]
                k_times = [results.enhanced_mle_time[i] for i in indices]
                
                row['mean_MSE'] = np.mean(k_mses)
                row['std_MSE'] = np.std(k_mses) if len(k_mses) > 1 else 0
                row['convergence_rate'] = np.mean(k_convs) * 100
                row['mean_time'] = np.mean(k_times)
                
                data_rows.append(row)
        
        # Add Phase 3 Signature results
        for K in self.signature_K_values:
            # Expected Signature
            if results.expected_sig_mse[K]:
                valid_mses = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                valid_convs = [x for x in results.expected_sig_convergence[K] if not np.isnan(x)]
                
                if valid_mses:
                    row = {'K': K, 'Phase': 'Phase2_ExpectedSignature_SmartInit'}
                    row['mean_MSE'] = np.mean(valid_mses)
                    row['std_MSE'] = np.std(valid_mses) if len(valid_mses) > 1 else 0
                    row['convergence_rate'] = np.mean(valid_convs) * 100 if valid_convs else 0
                    row['mean_time'] = np.mean(results.expected_sig_time[K])
                    data_rows.append(row)
            
            # Rescaled Signature
            if results.rescaled_sig_mse[K]:
                valid_mses = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                valid_convs = [x for x in results.rescaled_sig_convergence[K] if not np.isnan(x)]
                
                if valid_mses:
                    row = {'K': K, 'Phase': 'Phase2_RescaledSignature_SmartInit'}
                    row['mean_MSE'] = np.mean(valid_mses)
                    row['std_MSE'] = np.std(valid_mses) if len(valid_mses) > 1 else 0
                    row['convergence_rate'] = np.mean(valid_convs) * 100 if valid_convs else 0
                    row['mean_time'] = np.mean(results.rescaled_sig_time[K])
                    data_rows.append(row)
        
        # Add Phase 3 Method of Moments results (comprehensive baseline)
        for K in self.method_of_moments_K_values:
            row = {'K': K, 'Phase': 'Phase3_MethodOfMoments'}
            
            if K in results.method_of_moments_mse and results.method_of_moments_mse[K]:
                row['mean_MSE'] = np.mean(results.method_of_moments_mse[K])
                row['std_MSE'] = np.std(results.method_of_moments_mse[K])
                row['convergence_rate'] = np.mean(results.method_of_moments_convergence[K])
                row['mean_time'] = np.mean(results.method_of_moments_time[K])
            else:
                row['mean_MSE'] = np.nan
                row['std_MSE'] = np.nan
                row['convergence_rate'] = np.nan
                row['mean_time'] = np.nan
            
            data_rows.append(row)
        
        df = pd.DataFrame(data_rows)
        
        # Add optimal K histogram as separate rows
        histogram_rows = []
        for k, count in results.optimal_K_histogram.items():
            histogram_rows.append({
                'K': k,
                'Phase': 'OptimalK_Histogram',
                'mean_MSE': np.nan,
                'std_MSE': np.nan,
                'convergence_rate': np.nan,
                'mean_time': np.nan,
                'count': count
            })
        
        if histogram_rows:
            histogram_df = pd.DataFrame(histogram_rows)
            df = pd.concat([df, histogram_df], ignore_index=True)
        
        # Add summary statistics for plot regeneration
        summary_rows = []
        
        # Use cached statistics (computed once, reused everywhere)
        stats = self._compute_regime_statistics(results)
        
        if 'enhanced_mle' in stats:
            mle_stats = stats['enhanced_mle']
            summary_rows.append({
                'K': mle_stats['consensus_k'],
                'Phase': 'Enhanced_MLE_AllResults',
                'mean_MSE': mle_stats['mean_mse'],
                'std_MSE': mle_stats['std_mse'],
                'convergence_rate': mle_stats['mean_convergence'],
                'mean_time': np.mean(mle_stats['all_time']),
                'count': len(mle_stats['all_mse']),
                'consensus_k': mle_stats['consensus_k']
            })
            
            # Get pre-computed best signature results
            best_exp_mse = stats['best_expected']['mse']
            best_exp_k = stats['best_expected']['k']
            best_rsc_mse = stats['best_rescaled']['mse'] 
            best_rsc_k = stats['best_rescaled']['k']
            
            # Get pre-computed improvement calculations
            exp_improvement = stats['improvements']['expected_pct']
            rsc_improvement = stats['improvements']['rescaled_pct']
            
            summary_rows.append({
                'K': np.nan,
                'Phase': 'Improvement_Summary',
                'mean_MSE': np.nan,
                'std_MSE': np.nan,
                'convergence_rate': np.nan,
                'mean_time': np.nan,
                'count': np.nan,
                'enhanced_mle_baseline': mle_stats['mean_mse'],
                'best_expected_mse': best_exp_mse,
                'best_expected_k': best_exp_k,
                'expected_improvement_pct': exp_improvement,
                'best_rescaled_mse': best_rsc_mse,
                'best_rescaled_k': best_rsc_k,
                'rescaled_improvement_pct': rsc_improvement,
                'consensus_k': mle_stats['consensus_k']
            })
        
        if summary_rows:
            summary_df = pd.DataFrame(summary_rows)
            df = pd.concat([df, summary_df], ignore_index=True)
        
        filename_base = self.regime_name.lower().replace(', ', '_').replace(' ', '_')
        csv_path = os.path.join(save_dir, f'{filename_base}_results.csv')
        df.to_csv(csv_path, index=False)
        logger.info(f"Saved regime results to {csv_path}")
        logger.info(f"CSV contains all data needed to regenerate 4-plot analysis")
        
        return df


def perform_combined_regime_hypothesis_testing(all_regime_results, save_dir: str = 'plots/regime_studies'):
    """
    Perform hypothesis testing across all regimes combined.
    Tests signature methods vs Enhanced MLE using pooled data for maximum statistical power.
    
    Args:
        all_regime_results: Dictionary of regime results
        save_dir: Directory to save results
        
    Returns:
        Dictionary containing combined hypothesis testing results
    """
    from scipy import stats
    
    combined_results = {
        'combined_tests': {},
        'regime_summary': {}
    }
    
    # Collect all Enhanced MLE data across regimes
    all_enhanced_mle_data = []
    
    # Collect signature method data by K value across regimes
    all_expected_data = {K: [] for K in [32, 64, 256, 1024, 4096, 16384]}
    all_rescaled_data = {K: [] for K in [32, 64, 256, 1024, 4096, 16384]}
    
    for regime_name, results in all_regime_results.items():
        # Collect Enhanced MLE data
        if hasattr(results, 'enhanced_mle_mse') and results.enhanced_mle_mse:
            all_enhanced_mle_data.extend(results.enhanced_mle_mse)
        
        # Collect signature method data
        for K in [32, 64, 256, 1024, 4096, 16384]:
            if hasattr(results, 'expected_sig_mse') and K in results.expected_sig_mse:
                valid_expected = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                all_expected_data[K].extend(valid_expected)
            
            if hasattr(results, 'rescaled_sig_mse') and K in results.rescaled_sig_mse:
                valid_rescaled = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                all_rescaled_data[K].extend(valid_rescaled)
    
    # Test Expected Signature methods (pooled across regimes)
    for K in [32, 64, 256, 1024, 4096, 16384]:
        if len(all_expected_data[K]) >= 3 and len(all_enhanced_mle_data) >= 3:
            t_stat, p_value = stats.ttest_ind(all_expected_data[K], all_enhanced_mle_data)
            
            combined_results['combined_tests'][f'Expected_K{K}'] = {
                'method': 'Expected Signature',
                'K': K,
                'test_type': 'independent_t_test_pooled',
                't_statistic': t_stat,
                'p_value': p_value,
                'significant': p_value < 0.05,
                'improvement_direction': 'signature_better' if t_stat < 0 else 'mle_better',
                'mean_signature': np.mean(all_expected_data[K]),
                'mean_enhanced_mle': np.mean(all_enhanced_mle_data),
                'improvement_pct': (1 - np.mean(all_expected_data[K]) / np.mean(all_enhanced_mle_data)) * 100,
                'sample_size_sig': len(all_expected_data[K]),
                'sample_size_mle': len(all_enhanced_mle_data),
                'regimes_pooled': len(all_regime_results)
            }
    
    # Test Rescaled Signature methods (pooled across regimes)
    for K in [32, 64, 256, 1024, 4096, 16384]:
        if len(all_rescaled_data[K]) >= 3 and len(all_enhanced_mle_data) >= 3:
            t_stat, p_value = stats.ttest_ind(all_rescaled_data[K], all_enhanced_mle_data)
            
            combined_results['combined_tests'][f'Rescaled_K{K}'] = {
                'method': 'Rescaled Signature',
                'K': K,
                'test_type': 'independent_t_test_pooled',
                't_statistic': t_stat,
                'p_value': p_value,
                'significant': p_value < 0.05,
                'improvement_direction': 'signature_better' if t_stat < 0 else 'mle_better',
                'mean_signature': np.mean(all_rescaled_data[K]),
                'mean_enhanced_mle': np.mean(all_enhanced_mle_data),
                'improvement_pct': (1 - np.mean(all_rescaled_data[K]) / np.mean(all_enhanced_mle_data)) * 100,
                'sample_size_sig': len(all_rescaled_data[K]),
                'sample_size_mle': len(all_enhanced_mle_data),
                'regimes_pooled': len(all_regime_results)
            }
    
    return combined_results


def log_combined_hypothesis_results(combined_results):
    """Log combined regime hypothesis testing results."""
    logger.info(f"\n{'='*100}")
    logger.info(f"COMBINED REGIME HYPOTHESIS TESTING RESULTS")
    logger.info(f"Testing signature methods vs Enhanced MLE across ALL regimes")
    logger.info(f"{'='*100}")
    
    if not combined_results['combined_tests']:
        logger.info("No combined hypothesis tests performed (insufficient data)")
        return
    
    significant_improvements = []
    
    for test_name, result in combined_results['combined_tests'].items():
        method = result['method']
        K = result['K']
        p_val = result['p_value']
        significant = result['significant']
        improvement = result['improvement_pct']
        direction = result['improvement_direction']
        sample_size_sig = result['sample_size_sig']
        sample_size_mle = result['sample_size_mle']
        regimes_pooled = result['regimes_pooled']
        
        # Format significance
        sig_status = "SIGNIFICANT" if significant else "Not significant"
        direction_text = "Better" if direction == 'signature_better' else "Worse"
        
        logger.info(f"\n{method} (K={K}): {sig_status}")
        logger.info(f"  {direction_text} - p-value: {p_val:.4f}")
        logger.info(f"  Improvement: {improvement:+.1f}%")
        logger.info(f"  Sample sizes: Signature={sample_size_sig}, Enhanced MLE={sample_size_mle}")
        logger.info(f"  Regimes pooled: {regimes_pooled}")
        
        if significant and direction == 'signature_better':
            significant_improvements.append((method, K, improvement, p_val, sample_size_sig))
    
    # Summary
    logger.info(f"\n{'='*60}")
    logger.info(f"COMBINED REGIME STATISTICAL SUMMARY:")
    logger.info(f"{'='*60}")
    
    if significant_improvements:
        logger.info(f"STATISTICALLY SIGNIFICANT IMPROVEMENTS FOUND:")
        for method, K, improvement, p_val, n_samples in significant_improvements:
            logger.info(f"  {method} (K={K}): {improvement:.1f}% better")
            logger.info(f"    p-value: {p_val:.4f}, n={n_samples} samples")
    else:
        logger.info(f"No statistically significant improvements found across combined regimes")
    
    logger.info(f"\nHypothesis testing complete - results provide PhD-level statistical rigor")
    
    # Save combined hypothesis testing results to CSV
    detailed_results_dir = os.path.join(save_dir, 'detailed_results')
    save_combined_hypothesis_results_to_csv(combined_results, detailed_results_dir)
    
    return combined_results


def save_combined_hypothesis_results_to_csv(combined_results, save_dir: str = 'plots/regime_studies/detailed_results'):
    """Save combined hypothesis testing results to CSV file."""
    os.makedirs(save_dir, exist_ok=True)
    
    if not combined_results['combined_tests']:
        logger.info("No combined hypothesis testing data to save")
        return
    
    # Create DataFrame for combined hypothesis testing results
    combined_hypothesis_data = []
    
    for test_name, result in combined_results['combined_tests'].items():
        combined_hypothesis_data.append({
            'method': result['method'],
            'K': result['K'],
            'test_type': result['test_type'],
            't_statistic': result['t_statistic'],
            'p_value': result['p_value'],
            'significant': result['significant'],
            'improvement_direction': result['improvement_direction'],
            'mean_signature': result['mean_signature'],
            'mean_enhanced_mle': result['mean_enhanced_mle'],
            'improvement_pct': result['improvement_pct'],
            'sample_size_signature': result['sample_size_sig'],
            'sample_size_enhanced_mle': result['sample_size_mle'],
            'regimes_pooled': result['regimes_pooled']
        })
    
    df = pd.DataFrame(combined_hypothesis_data)
    
    # Save to CSV
    csv_path = os.path.join(save_dir, 'combined_regime_hypothesis_testing.csv')
    df.to_csv(csv_path, index=False)
    
    logger.info(f"Saved combined hypothesis testing results to {csv_path}")
    
    return df


def run_all_regime_experiments(n_monte_carlo: int = 10, device=None, use_parallel: bool = True, max_workers: Optional[int] = None, config: ExperimentConfig = None):
    """
    Run experiments for all 4 parameter regimes.
    
    Args:
        n_monte_carlo: Number of Monte Carlo runs per regime
        device: Computing device
        use_parallel: Whether to use parallel execution for MC runs (default: True)
        max_workers: Number of parallel workers (default: min(8, n_monte_carlo))
        config: Centralized experiment configuration for parameters
    
    Returns:
        Dictionary of results for all regimes
    """
    import json
    from datetime import datetime
    
    device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Use provided config or default to optimized preset
    config = config if config is not None else ConfigPresets.optimized()
    
    # Create timestamped folder in plots directory
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    timestamped_folder = f"plots/regime_studies_{timestamp}"
    os.makedirs(timestamped_folder, exist_ok=True)
    
    # Create experiment parameters JSON with centralized configuration
    experiment_params = {
        "timestamp": timestamp,
        "n_monte_carlo": n_monte_carlo,
        "use_parallel": use_parallel,
        "max_workers": max_workers,
        "device": str(device),
        "regimes": list(RegimeOptimizationExperiment.REGIME_CONFIGS.keys()),
        "optimization_parameters": config.to_dict(),
        "k_values": {
            "enhanced_mle": [1, 2, 4, 8, 16],
            "expected_signature": [16, 64, 256, 1024, 4096],
            "rescaled_signature": [16, 64, 256, 1024, 4096]
        }
    }
    
    # Save parameters to JSON file
    params_file = os.path.join(timestamped_folder, "experiment_parameters.json")
    with open(params_file, 'w') as f:
        json.dump(experiment_params, f, indent=2)
    
    logger.info(f"Created timestamped experiment folder: {timestamped_folder}")
    logger.info(f"Saved experiment parameters to: {params_file}")
    
    # Log parallel execution status
    if use_parallel:
        logger.info(f"\n{'='*80}")
        logger.info(f"PARALLEL MONTE CARLO BATCHING ENABLED")
        logger.info(f"Workers per regime: {max_workers or min(8, n_monte_carlo)}")
        logger.info(f"Expected speedup: 3-6x for 10 MC runs")
        logger.info(f"{'='*80}")
    
    all_results = {}
    total_start_time = time.time()
    
    for regime_name in RegimeOptimizationExperiment.REGIME_CONFIGS.keys():
        logger.info(f"\n{'='*80}")
        logger.info(f"PROCESSING REGIME: {regime_name}")
        logger.info(f"{'='*80}")
        
        regime_start_time = time.time()
        
        # Create experiment for this regime
        experiment = RegimeOptimizationExperiment(
            regime_name=regime_name,
            n_monte_carlo=n_monte_carlo,
            device=device,
            config=config
        )
        
        # Run experiment with parallel flag
        # Note: run_regime_experiment now automatically generates plots and saves results
        regime_results = experiment.run_regime_experiment(use_parallel=use_parallel, max_workers=max_workers, save_dir=timestamped_folder)
        
        all_results[regime_name] = regime_results
        
        regime_time = time.time() - regime_start_time
        logger.info(f"Regime {regime_name} completed in {regime_time:.1f} seconds")
        
        # Clear cache if using optimizations
        if OPTIMIZATIONS_AVAILABLE:
            clear_generator_cache()
    
    # Generate comparison plots in timestamped folder
    generate_regime_comparison_plots(all_results, timestamped_folder)
    
    # Perform combined regime hypothesis testing in timestamped folder
    combined_hypothesis_results = perform_combined_regime_hypothesis_testing(all_results, timestamped_folder)
    
    total_time = time.time() - total_start_time
    logger.info(f"\n{'='*80}")
    logger.info(f"ALL REGIMES COMPLETED IN {total_time:.1f} seconds ({total_time/60:.1f} minutes)")
    logger.info(f"{'='*80}")
    
    return all_results


def _get_all_enhanced_mle_mse(results) -> float:
    """Helper function to get Enhanced MLE MSE using ALL results for full statistical power."""
    # Handle both RegimeResults objects and dictionaries
    if hasattr(results, 'enhanced_mle_mse'):
        enhanced_mle_data = results.enhanced_mle_mse
    elif isinstance(results, dict) and 'enhanced_mle_mse' in results:
        enhanced_mle_data = results['enhanced_mle_mse']
    else:
        return float('inf')
    
    if not enhanced_mle_data:
        return float('inf')
    
    # Use ALL Enhanced MLE results for statistics (no filtering)
    return np.mean(enhanced_mle_data)


def generate_regime_comparison_plots(all_results: Dict[str, RegimeResults], 
                                    save_dir: str = 'plots/regime_studies'):
    """
    Generate comparison plots across all regimes using consensus K for Enhanced MLE.
    
    Args:
        all_results: Dictionary of RegimeResults for all regimes
        save_dir: Directory to save plots
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # Create comparison summary plot
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    for idx, (regime_name, results) in enumerate(all_results.items()):
        ax = axes[idx]
        
        # Plot best MSE for each method
        methods = ['MLE', 'Expected Sig', 'Rescaled Sig']
        best_mses = []
        
        # Find best Enhanced MLE (Phase 2) - use ALL results for full statistical power
        best_mle = _get_all_enhanced_mle_mse(results)
        best_mses.append(best_mle)
        
        # Find best Expected Sig (Phase 3)
        best_exp = float('inf')
        for K in results.expected_sig_mse:
            if results.expected_sig_mse[K]:
                valid_mses = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_exp:
                        best_exp = mean_mse
        best_mses.append(best_exp)
        
        # Find best Rescaled Sig (Phase 3)
        best_rsc = float('inf')
        for K in results.rescaled_sig_mse:
            if results.rescaled_sig_mse[K]:
                valid_mses = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_rsc:
                        best_rsc = mean_mse
        best_mses.append(best_rsc)
        
        colors = ['#2E86AB', '#A23B72', '#F18F01']
        bars = ax.bar(methods, best_mses, color=colors)
        
        ax.set_ylabel('Best MSE', fontsize=12)
        ax.set_title(regime_name, fontsize=14)
        ax.set_ylim(0, max(best_mses) * 1.1)
        
        # Add value labels on bars
        for bar, val in zip(bars, best_mses):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:.3f}', ha='center', va='bottom', fontsize=10)
    
    plt.suptitle('Best MSE Comparison Across Parameter Regimes', fontsize=16, y=1.02)
    plt.tight_layout()
    
    plot_path = os.path.join(save_dir, 'regime_comparison_summary.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    logger.info(f"Saved comparison plot to {plot_path}")
    
    plt.close()
    
    # Create convergence analysis comparison
    fig, ax = plt.subplots(figsize=(14, 8))
    
    regime_names_short = {
        "Slow Reversion, Low Volatility": "Slow-Low",
        "Fast Reversion, Low Volatility": "Fast-Low",
        "Slow Reversion, High Volatility": "Slow-High",
        "Fast Reversion, High Volatility": "Fast-High"
    }
    
    x = np.arange(len(regime_names_short))
    width = 0.25
    
    exp_improvements = []
    rsc_improvements = []
    exp_k_values = []
    rsc_k_values = []
    
    for regime_name, results in all_results.items():
        # Calculate signature method improvements over Enhanced MLE (Phase 2) - use ALL results
        best_mle = _get_all_enhanced_mle_mse(results)
        
        best_exp = float('inf')
        best_exp_k = None
        for K in results.expected_sig_mse:
            if results.expected_sig_mse[K]:
                valid_mses = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_exp:
                        best_exp = mean_mse
                        best_exp_k = K
        
        best_rsc = float('inf')
        best_rsc_k = None
        for K in results.rescaled_sig_mse:
            if results.rescaled_sig_mse[K]:
                valid_mses = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_rsc:
                        best_rsc = mean_mse
                        best_rsc_k = K
        
        exp_improvements.append((1 - best_exp/best_mle) * 100 if best_mle > 0 else 0)
        rsc_improvements.append((1 - best_rsc/best_mle) * 100 if best_mle > 0 else 0)
        exp_k_values.append(best_exp_k)
        rsc_k_values.append(best_rsc_k)
    
    # Create grouped bar chart - SIGNATURE METHODS ONLY with optimal K values
    width = 0.35  # Adjusted width for 2 bars instead of 3
    bars1 = ax.bar(x - width/2, exp_improvements, width, label='Expected Signature', color='#A23B72')
    bars2 = ax.bar(x + width/2, rsc_improvements, width, label='Rescaled Signature', color='#F18F01')
    
    # Add optimal K values as text labels on the bars
    for i, (bar1, bar2, exp_k, rsc_k) in enumerate(zip(bars1, bars2, exp_k_values, rsc_k_values)):
        if exp_k is not None:
            ax.text(bar1.get_x() + bar1.get_width()/2., bar1.get_height() + 1,
                   f'K={exp_k}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        if rsc_k is not None:
            ax.text(bar2.get_x() + bar2.get_width()/2., bar2.get_height() + 1,
                   f'K={rsc_k}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    ax.set_xlabel('Parameter Regime', fontsize=14)
    ax.set_ylabel('Improvement over Enhanced MLE [%]', fontsize=14)
    ax.set_title('Signature Method Performance Improvement Across Regimes', fontsize=16)
    ax.set_xticks(x)
    ax.set_xticklabels(regime_names_short.values())
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    
    plot_path = os.path.join(save_dir, 'convergence_analysis_by_regime.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    logger.info(f"Saved convergence analysis to {plot_path}")
    
    plt.close()
    
    # Save summary statistics
    summary_data = []
    for regime_name, results in all_results.items():
        row = {'Regime': regime_name}
        
        # Find best results for each method
        # Enhanced MLE results (Phase 2) - use ALL results for full statistical power
        best_mle_mse = _get_all_enhanced_mle_mse(results)
        # Find consensus K for plotting (design choice)
        mode_k = max(results.optimal_K_histogram, key=results.optimal_K_histogram.get) if results.optimal_K_histogram else None
        best_mle_k = mode_k
        
        best_exp_mse = float('inf')
        best_exp_k = None
        for K in results.expected_sig_mse:
            if results.expected_sig_mse[K]:
                valid_mses = [x for x in results.expected_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_exp_mse:
                        best_exp_mse = mean_mse
                        best_exp_k = K
        
        best_rsc_mse = float('inf')
        best_rsc_k = None
        for K in results.rescaled_sig_mse:
            if results.rescaled_sig_mse[K]:
                valid_mses = [x for x in results.rescaled_sig_mse[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_rsc_mse:
                        best_rsc_mse = mean_mse
                        best_rsc_k = K
        
        row['EnhancedMLE_best_K'] = best_mle_k
        row['EnhancedMLE_best_MSE'] = best_mle_mse
        row['ExpSig_best_K'] = best_exp_k
        row['ExpSig_best_MSE'] = best_exp_mse
        row['RscSig_best_K'] = best_rsc_k
        row['RscSig_best_MSE'] = best_rsc_mse
        
        if best_mle_mse > 0:
            row['ExpSig_improvement_%'] = (1 - best_exp_mse/best_mle_mse) * 100
            row['RscSig_improvement_%'] = (1 - best_rsc_mse/best_mle_mse) * 100
        else:
            row['ExpSig_improvement_%'] = 0
            row['RscSig_improvement_%'] = 0
        
        summary_data.append(row)
    
    summary_df = pd.DataFrame(summary_data)
    summary_path = os.path.join(save_dir, 'detailed_results', 'regime_summary_statistics.csv')
    os.makedirs(os.path.dirname(summary_path), exist_ok=True)
    summary_df.to_csv(summary_path, index=False)
    logger.info(f"Saved summary statistics to {summary_path}")
    
    # Generate combined regime analysis
    _generate_combined_regime_analysis(all_results, save_dir)
    
    logger.info("\n" + "="*80)
    logger.info("ALL REGIME EXPERIMENTS COMPLETED")
    logger.info("="*80)


def _generate_combined_landscape_plot(all_results: Dict, save_dir: str = 'plots/regime_studies'):
    """
    Generate combined regime landscape plot aggregating data across all regimes.
    Creates confidence intervals by treating each regime's Monte Carlo runs as independent samples.
    
    Args:
        all_results: Dictionary of regime results
        save_dir: Directory to save plots
    """
    from scipy import stats
    logger.info("Generating combined regime landscape plot...")
    
    # Aggregate all data across regimes
    combined_analytical_ou = {}  # K -> [mse_values] (Phase 0)
    combined_method_of_moments = {}  # K -> [mse_values] (Phase 0)
    combined_analytical_ou_conv = {}  # K -> [convergence_rates] (Phase 0)
    combined_mom_conv = {}  # K -> [convergence_rates] (Phase 0)
    combined_quick_mle = {}  # K -> [mse_values]
    combined_enhanced_mle = []  # All enhanced MLE MSE values
    combined_expected_sig = {}  # K -> [mse_values]  
    combined_rescaled_sig = {}  # K -> [mse_values]
    combined_convergence = {}  # K -> [convergence_rates]
    combined_optimal_k = []  # All optimal K values from Phase 1
    
    # Collect all K values used across regimes
    quick_mle_k_values = [1, 4, 16, 64, 256]  # Standard values
    signature_k_values = [64, 256, 1024, 4096, 16384, 65536, 262144]  # Standard values
    
    # Initialize data structures
    for K in quick_mle_k_values:
        combined_analytical_ou[K] = []
        combined_method_of_moments[K] = []
        combined_analytical_ou_conv[K] = []
        combined_mom_conv[K] = []
        combined_quick_mle[K] = []
        combined_convergence[K] = []
    for K in signature_k_values:
        combined_expected_sig[K] = []
        combined_rescaled_sig[K] = []
    
    # Aggregate data from all regimes
    for regime_name, results in all_results.items():
        # Handle both dictionary and object formats
        analytical_ou_mse_data = results.get('analytical_ou_mse', {}) if isinstance(results, dict) else getattr(results, 'analytical_ou_mse', {})
        analytical_ou_conv_data = results.get('analytical_ou_convergence', {}) if isinstance(results, dict) else getattr(results, 'analytical_ou_convergence', {})
        mom_mse_data = results.get('method_of_moments_mse', {}) if isinstance(results, dict) else getattr(results, 'method_of_moments_mse', {})
        mom_conv_data = results.get('method_of_moments_convergence', {}) if isinstance(results, dict) else getattr(results, 'method_of_moments_convergence', {})
        quick_mle_mse_data = results.get('quick_mle_mse', {}) if isinstance(results, dict) else getattr(results, 'quick_mle_mse', {})
        quick_mle_conv_data = results.get('quick_mle_convergence', {}) if isinstance(results, dict) else getattr(results, 'quick_mle_convergence', {})
        enhanced_mle_data = results.get('enhanced_mle_mse', []) if isinstance(results, dict) else getattr(results, 'enhanced_mle_mse', [])
        optimal_k_data = results.get('optimal_K_histogram', {}) if isinstance(results, dict) else getattr(results, 'optimal_K_histogram', {})
        expected_sig_data = results.get('expected_sig_mse', {}) if isinstance(results, dict) else getattr(results, 'expected_sig_mse', {})
        rescaled_sig_data = results.get('rescaled_sig_mse', {}) if isinstance(results, dict) else getattr(results, 'rescaled_sig_mse', {})
        
        # Classical method data (Phase 0)
        for K in quick_mle_k_values:
            if K in analytical_ou_mse_data and analytical_ou_mse_data[K]:
                combined_analytical_ou[K].extend(analytical_ou_mse_data[K])
                combined_analytical_ou_conv[K].extend(analytical_ou_conv_data.get(K, []))
            
            if K in mom_mse_data and mom_mse_data[K]:
                combined_method_of_moments[K].extend(mom_mse_data[K])
                combined_mom_conv[K].extend(mom_conv_data.get(K, []))
        
        # Quick MLE data (Phase 1)
        for K in quick_mle_k_values:
            if K in quick_mle_mse_data and quick_mle_mse_data[K]:
                combined_quick_mle[K].extend(quick_mle_mse_data[K])
                combined_convergence[K].extend(quick_mle_conv_data.get(K, []))
        
        # Enhanced MLE data (Phase 2)
        if enhanced_mle_data:
            combined_enhanced_mle.extend(enhanced_mle_data)
        
        # Optimal K from Phase 1
        if optimal_k_data:
            optimal_k = max(optimal_k_data, key=optimal_k_data.get)
            combined_optimal_k.append(optimal_k)
        
        # Signature method data (Phase 3)
        for K in signature_k_values:
            if K in expected_sig_data and expected_sig_data[K]:
                valid_mses = [x for x in expected_sig_data[K] if not np.isnan(x)]
                combined_expected_sig[K].extend(valid_mses)
            
            if K in rescaled_sig_data and rescaled_sig_data[K]:
                valid_mses = [x for x in rescaled_sig_data[K] if not np.isnan(x)]
                combined_rescaled_sig[K].extend(valid_mses)
    
    # Create 2x2 subplot layout (same as individual regime plots)
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))
    fig.suptitle('Combined Regime Optimization Landscape Analysis: All Regimes Combined', fontsize=20, y=0.98)
    
    # Left panel: MSE vs K with confidence intervals
    ax1.set_xscale('log', base=2)
    ax1.set_yscale('log')
    ax1.set_xlabel('Number of Blocks (K)', fontsize=14)
    ax1.set_ylabel('Mean Squared Error', fontsize=14)
    ax1.set_title('4-Phase Hierarchical Calibration: Combined Regimes', fontsize=16)
    ax1.grid(True, alpha=0.3)
    
    # Plot Phase 0: Classical methods with confidence intervals
    analytical_ou_k_vals = []
    analytical_ou_mse_means = []
    analytical_ou_mse_stds = []
    
    for K in quick_mle_k_values:
        if combined_analytical_ou[K]:
            analytical_ou_k_vals.append(K)
            analytical_ou_mse_means.append(np.mean(combined_analytical_ou[K]))
            analytical_ou_mse_stds.append(np.std(combined_analytical_ou[K]) if len(combined_analytical_ou[K]) > 1 else 0)
    
    if analytical_ou_k_vals:
        ax1.errorbar(analytical_ou_k_vals, analytical_ou_mse_means, yerr=analytical_ou_mse_stds,
                    fmt='D--', label='Analytical OU (Phase 0)', markersize=5, 
                    linewidth=1.5, color='#8B4513', alpha=0.8, capsize=4)
    
    mom_k_vals = []
    mom_mse_means = []
    mom_mse_stds = []
    
    for K in quick_mle_k_values:
        if combined_method_of_moments[K]:
            mom_k_vals.append(K)
            mom_mse_means.append(np.mean(combined_method_of_moments[K]))
            mom_mse_stds.append(np.std(combined_method_of_moments[K]) if len(combined_method_of_moments[K]) > 1 else 0)
    
    if mom_k_vals:
        ax1.errorbar(mom_k_vals, mom_mse_means, yerr=mom_mse_stds,
                    fmt='p--', label='Method of Moments (Phase 0)', markersize=5, 
                    linewidth=1.5, color='#4B0082', alpha=0.8, capsize=4)
    
    # Plot Phase 1: Quick MLE with confidence intervals
    quick_k_vals = []
    quick_mse_means = []
    quick_mse_stds = []
    
    for K in quick_mle_k_values:
        if combined_quick_mle[K]:
            quick_k_vals.append(K)
            quick_mse_means.append(np.mean(combined_quick_mle[K]))
            quick_mse_stds.append(np.std(combined_quick_mle[K]) if len(combined_quick_mle[K]) > 1 else 0)
    
    if quick_k_vals:
        ax1.errorbar(quick_k_vals, quick_mse_means, yerr=quick_mse_stds,
                    fmt='s-', label='Quick MLE (Phase 1)', markersize=6, 
                    linewidth=2, color='#2E86AB', alpha=0.7, capsize=5)
    
    # Plot Phase 2: Enhanced MLE (single point with confidence interval)
    if combined_enhanced_mle:
        enhanced_mle_mean = np.mean(combined_enhanced_mle)
        enhanced_mle_std = np.std(combined_enhanced_mle) if len(combined_enhanced_mle) > 1 else 0
        
        # Get consensus optimal K for x-position
        if combined_optimal_k:
            consensus_k = max(set(combined_optimal_k), key=combined_optimal_k.count)
            ax1.errorbar([consensus_k], [enhanced_mle_mean], yerr=[enhanced_mle_std],
                        fmt='X', markersize=12, color='#2E86AB', 
                        label='Enhanced MLE (Phase 2)', capsize=5)
    
    # Plot Phase 3: Signature methods with confidence intervals
    exp_k_vals = []
    exp_mse_means = []
    exp_mse_stds = []
    
    for K in signature_k_values:
        if combined_expected_sig[K]:
            exp_k_vals.append(K)
            exp_mse_means.append(np.mean(combined_expected_sig[K]))
            exp_mse_stds.append(np.std(combined_expected_sig[K]) if len(combined_expected_sig[K]) > 1 else 0)
    
    if exp_k_vals:
        ax1.errorbar(exp_k_vals, exp_mse_means, yerr=exp_mse_stds,
                    fmt='o-', label='Expected Signature (Phase 3)', markersize=8,
                    linewidth=2, color='#A23B72', capsize=5)
    
    rsc_k_vals = []
    rsc_mse_means = []
    rsc_mse_stds = []
    
    for K in signature_k_values:
        if combined_rescaled_sig[K]:
            rsc_k_vals.append(K)
            rsc_mse_means.append(np.mean(combined_rescaled_sig[K]))
            rsc_mse_stds.append(np.std(combined_rescaled_sig[K]) if len(combined_rescaled_sig[K]) > 1 else 0)
    
    if rsc_k_vals:
        ax1.errorbar(rsc_k_vals, rsc_mse_means, yerr=rsc_mse_stds,
                    fmt='^-', label='Rescaled Signature (Phase 3)', markersize=8,
                    linewidth=2, color='#F18F01', capsize=5)
    
    ax1.legend(loc='upper right', fontsize=12)
    
    # Right panel: Convergence rates
    ax2.set_xscale('log', base=2)
    ax2.set_xlabel('Number of Blocks (K)', fontsize=14)
    ax2.set_ylabel('Convergence Rate (%)', fontsize=14)
    ax2.set_title('Convergence Rates: Combined Regimes', fontsize=16)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(-5, 105)
    
    # Plot convergence rates with confidence intervals
    conv_k_vals = []
    conv_means = []
    conv_stds = []
    
    for K in quick_mle_k_values:
        if combined_convergence[K]:
            conv_k_vals.append(K)
            conv_rate = np.mean(combined_convergence[K]) * 100
            conv_std = np.std(combined_convergence[K]) * 100 if len(combined_convergence[K]) > 1 else 0
            conv_means.append(conv_rate)
            conv_stds.append(conv_std)
    
    if conv_k_vals:
        ax2.errorbar(conv_k_vals, conv_means, yerr=conv_stds,
                    fmt='s-', label='Quick MLE', markersize=6, 
                    color='#2E86AB', capsize=5)
    
    # Enhanced MLE convergence (assume 100% at optimal K)
    if combined_optimal_k:
        consensus_k = max(set(combined_optimal_k), key=combined_optimal_k.count)
        ax2.plot([consensus_k], [100], 'X', markersize=12, color='#2E86AB', 
                label='Enhanced MLE')
    
    # Signature method convergence (calculate from valid results)
    for K in signature_k_values:
        if combined_expected_sig[K] or combined_rescaled_sig[K]:
            # Calculate convergence based on non-NaN results
            exp_conv = len(combined_expected_sig[K]) / max(1, len(all_results) * 2) * 100 if combined_expected_sig[K] else 0
            rsc_conv = len(combined_rescaled_sig[K]) / max(1, len(all_results) * 2) * 100 if combined_rescaled_sig[K] else 0
            
            if exp_conv > 0:
                ax2.plot([K], [exp_conv], 'o', markersize=8, color='#A23B72', alpha=0.7)
            if rsc_conv > 0:
                ax2.plot([K], [rsc_conv], '^', markersize=8, color='#F18F01', alpha=0.7)
    
    ax2.legend(loc='best', fontsize=12)
    
    # Bottom left: Optimal K histogram (combined)
    ax3.set_xlabel('Optimal K Value (Phase 1)', fontsize=14)
    ax3.set_ylabel('Frequency', fontsize=14)
    ax3.set_title('Optimal K Selection Histogram: Combined Regimes', fontsize=16)
    
    if combined_optimal_k:
        k_counts = {}
        for k in combined_optimal_k:
            k_counts[k] = k_counts.get(k, 0) + 1
        
        k_values = list(k_counts.keys())
        frequencies = list(k_counts.values())
        
        bars = ax3.bar(k_values, frequencies, alpha=0.7, color='steelblue')
        ax3.set_xscale('log', base=2)
        
        # Add frequency labels
        for bar, freq in zip(bars, frequencies):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{freq}', ha='center', va='bottom', fontsize=12)
    
    # Bottom right: Signature method improvement with optimal K labels
    ax4.set_ylabel('Improvement over Enhanced MLE (%)', fontsize=14)
    ax4.set_title('Signature Method Improvement vs Enhanced MLE: Combined Regimes', fontsize=16)
    ax4.grid(True, alpha=0.3, axis='y')
    ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    
    # Calculate improvements with optimal K
    if combined_enhanced_mle:
        enhanced_mle_mean = np.mean(combined_enhanced_mle)
        
        # Find best performance for each signature method
        best_exp_mse = float('inf')
        best_exp_k = None
        for K in signature_k_values:
            if combined_expected_sig[K]:
                mean_mse = np.mean(combined_expected_sig[K])
                if mean_mse < best_exp_mse:
                    best_exp_mse = mean_mse
                    best_exp_k = K
        
        best_rsc_mse = float('inf')
        best_rsc_k = None
        for K in signature_k_values:
            if combined_rescaled_sig[K]:
                mean_mse = np.mean(combined_rescaled_sig[K])
                if mean_mse < best_rsc_mse:
                    best_rsc_mse = mean_mse
                    best_rsc_k = K
        
        # Calculate improvements
        exp_improvement = (1 - best_exp_mse/enhanced_mle_mean) * 100 if enhanced_mle_mean > 0 else 0
        rsc_improvement = (1 - best_rsc_mse/enhanced_mle_mean) * 100 if enhanced_mle_mean > 0 else 0
        
        methods = ['Expected Signature', 'Rescaled Signature']
        improvements = [exp_improvement, rsc_improvement]
        optimal_ks = [best_exp_k, best_rsc_k]
        colors = ['#A23B72', '#F18F01']
        
        bars = ax4.bar(methods, improvements, color=colors, alpha=0.7)
        
        # Add improvement percentage and optimal K labels
        for bar, improvement, opt_k in zip(bars, improvements, optimal_ks):
            height = bar.get_height()
            y_pos = height + (0.02 * max(abs(min(improvements)), max(improvements)))
            
            ax4.text(bar.get_x() + bar.get_width()/2., y_pos,
                    f'{improvement:+.1f}%\n(K={opt_k})', 
                    ha='center', va='bottom' if height >= 0 else 'top', 
                    fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    
    # Save plot
    plot_path = os.path.join(save_dir, 'combined_regime_enhanced_landscape.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    logger.info(f"Saved combined regime landscape plot to {plot_path}")
    
    plt.close()
    
    # Save comprehensive data for the combined landscape plot
    _save_combined_landscape_data(
        combined_quick_mle, combined_enhanced_mle, combined_expected_sig, combined_rescaled_sig,
        combined_convergence, combined_optimal_k, all_results, save_dir
    )


def _save_combined_landscape_data(combined_quick_mle, combined_enhanced_mle, combined_expected_sig, 
                                 combined_rescaled_sig, combined_convergence, combined_optimal_k, 
                                 all_results, save_dir):
    """
    Save comprehensive data for the combined landscape plot.
    
    Args:
        combined_*: Aggregated data dictionaries from _generate_combined_landscape_plot
        all_results: Original results from all regimes
        save_dir: Directory to save data files
    """
    import pandas as pd
    
    detailed_dir = os.path.join(save_dir, 'detailed_results')
    os.makedirs(detailed_dir, exist_ok=True)
    
    # 1. Combined K-by-K Performance Data
    performance_data = []
    
    # Quick MLE data
    for K in sorted(combined_quick_mle.keys()):
        if combined_quick_mle[K]:
            data = combined_quick_mle[K]
            conv_data = combined_convergence[K]
            performance_data.append({
                'K': K,
                'Method': 'Quick_MLE',
                'Phase': 'Phase1',
                'n_samples': len(data),
                'mean_MSE': np.mean(data),
                'std_MSE': np.std(data) if len(data) > 1 else 0,
                'min_MSE': np.min(data),
                'max_MSE': np.max(data),
                'median_MSE': np.median(data),
                'mean_convergence': np.mean(conv_data) * 100 if conv_data else 0,
                'convergence_samples': len([x for x in conv_data if x > 0.5]) if conv_data else 0
            })
    
    # Enhanced MLE data (all at consensus K)
    if combined_enhanced_mle and combined_optimal_k:
        consensus_k = max(set(combined_optimal_k), key=combined_optimal_k.count)
        data = combined_enhanced_mle
        performance_data.append({
            'K': consensus_k,
            'Method': 'Enhanced_MLE',
            'Phase': 'Phase2',
            'n_samples': len(data),
            'mean_MSE': np.mean(data),
            'std_MSE': np.std(data) if len(data) > 1 else 0,
            'min_MSE': np.min(data),
            'max_MSE': np.max(data),
            'median_MSE': np.median(data),
            'mean_convergence': 100.0,  # Enhanced MLE always converges
            'convergence_samples': len(data)
        })
    
    # Expected Signature data
    for K in sorted(combined_expected_sig.keys()):
        if combined_expected_sig[K]:
            data = combined_expected_sig[K]
            # Calculate convergence rate based on successful runs vs total regimes
            total_possible = len(all_results) * 2  # Assume 2 Monte Carlo per regime average
            convergence_rate = len(data) / total_possible * 100
            performance_data.append({
                'K': K,
                'Method': 'Expected_Signature',
                'Phase': 'Phase3',
                'n_samples': len(data),
                'mean_MSE': np.mean(data),
                'std_MSE': np.std(data) if len(data) > 1 else 0,
                'min_MSE': np.min(data),
                'max_MSE': np.max(data),
                'median_MSE': np.median(data),
                'mean_convergence': convergence_rate,
                'convergence_samples': len(data)
            })
    
    # Rescaled Signature data
    for K in sorted(combined_rescaled_sig.keys()):
        if combined_rescaled_sig[K]:
            data = combined_rescaled_sig[K]
            total_possible = len(all_results) * 2
            convergence_rate = len(data) / total_possible * 100
            performance_data.append({
                'K': K,
                'Method': 'Rescaled_Signature',
                'Phase': 'Phase3',
                'n_samples': len(data),
                'mean_MSE': np.mean(data),
                'std_MSE': np.std(data) if len(data) > 1 else 0,
                'min_MSE': np.min(data),
                'max_MSE': np.max(data),
                'median_MSE': np.median(data),
                'mean_convergence': convergence_rate,
                'convergence_samples': len(data)
            })
    
    # Save K-by-K performance
    perf_df = pd.DataFrame(performance_data)
    perf_path = os.path.join(detailed_dir, 'combined_landscape_performance_by_k.csv')
    perf_df.to_csv(perf_path, index=False)
    logger.info(f"Saved combined K-by-K performance data to {perf_path}")
    
    # 2. Raw Combined Data (for reproducibility)
    raw_data = []
    
    # Add all raw data points with regime labels
    for regime_name, results in all_results.items():
        quick_mle_data = results.get('quick_mle_mse', {}) if isinstance(results, dict) else getattr(results, 'quick_mle_mse', {})
        enhanced_mle_data = results.get('enhanced_mle_mse', []) if isinstance(results, dict) else getattr(results, 'enhanced_mle_mse', [])
        expected_sig_data = results.get('expected_sig_mse', {}) if isinstance(results, dict) else getattr(results, 'expected_sig_mse', {})
        rescaled_sig_data = results.get('rescaled_sig_mse', {}) if isinstance(results, dict) else getattr(results, 'rescaled_sig_mse', {})
        
        # Quick MLE raw data
        for K, mse_list in quick_mle_data.items():
            for i, mse in enumerate(mse_list):
                raw_data.append({
                    'regime': regime_name,
                    'monte_carlo_run': i,
                    'method': 'Quick_MLE',
                    'K': K,
                    'MSE': mse,
                    'phase': 'Phase1'
                })
        
        # Enhanced MLE raw data
        for i, mse in enumerate(enhanced_mle_data):
            raw_data.append({
                'regime': regime_name,
                'monte_carlo_run': i,
                'method': 'Enhanced_MLE',
                'K': 'consensus',  # Uses optimal K from Phase 1
                'MSE': mse,
                'phase': 'Phase2'
            })
        
        # Signature methods raw data
        for K, mse_list in expected_sig_data.items():
            for i, mse in enumerate(mse_list):
                if not np.isnan(mse):
                    raw_data.append({
                        'regime': regime_name,
                        'monte_carlo_run': i,
                        'method': 'Expected_Signature',
                        'K': K,
                        'MSE': mse,
                        'phase': 'Phase3'
                    })
        
        for K, mse_list in rescaled_sig_data.items():
            for i, mse in enumerate(mse_list):
                if not np.isnan(mse):
                    raw_data.append({
                        'regime': regime_name,
                        'monte_carlo_run': i,
                        'method': 'Rescaled_Signature',
                        'K': K,
                        'MSE': mse,
                        'phase': 'Phase3'
                    })
    
    # Save raw combined data
    raw_df = pd.DataFrame(raw_data)
    raw_path = os.path.join(detailed_dir, 'combined_landscape_raw_data.csv')
    raw_df.to_csv(raw_path, index=False)
    logger.info(f"Saved combined raw data to {raw_path}")
    
    # 3. Optimal K Selection Statistics
    optimal_k_data = []
    k_counts = {}
    for k in combined_optimal_k:
        k_counts[k] = k_counts.get(k, 0) + 1
    
    for k, count in k_counts.items():
        optimal_k_data.append({
            'optimal_K': k,
            'frequency': count,
            'percentage': count / len(combined_optimal_k) * 100,
            'total_regimes': len(combined_optimal_k)
        })
    
    # Save optimal K statistics
    opt_df = pd.DataFrame(optimal_k_data)
    opt_path = os.path.join(detailed_dir, 'combined_optimal_k_statistics.csv')
    opt_df.to_csv(opt_path, index=False)
    logger.info(f"Saved optimal K statistics to {opt_path}")
    
    # 4. Method Comparison Summary (best performance for each method)
    comparison_data = []
    
    # Find best performance for each method
    if combined_enhanced_mle:
        best_enhanced_mle = np.mean(combined_enhanced_mle)
        comparison_data.append({
            'method': 'Enhanced_MLE',
            'best_MSE': best_enhanced_mle,
            'optimal_K': 'consensus',
            'n_successful_runs': len(combined_enhanced_mle),
            'success_rate': 100.0
        })
    
    # Expected Signature
    best_exp_mse = float('inf')
    best_exp_k = None
    exp_successful_runs = 0
    for K in combined_expected_sig:
        if combined_expected_sig[K]:
            mean_mse = np.mean(combined_expected_sig[K])
            if mean_mse < best_exp_mse:
                best_exp_mse = mean_mse
                best_exp_k = K
                exp_successful_runs = len(combined_expected_sig[K])
    
    if not np.isinf(best_exp_mse):
        total_possible = len(all_results) * 2
        comparison_data.append({
            'method': 'Expected_Signature',
            'best_MSE': best_exp_mse,
            'optimal_K': best_exp_k,
            'n_successful_runs': exp_successful_runs,
            'success_rate': exp_successful_runs / total_possible * 100
        })
    
    # Rescaled Signature
    best_rsc_mse = float('inf')
    best_rsc_k = None
    rsc_successful_runs = 0
    for K in combined_rescaled_sig:
        if combined_rescaled_sig[K]:
            mean_mse = np.mean(combined_rescaled_sig[K])
            if mean_mse < best_rsc_mse:
                best_rsc_mse = mean_mse
                best_rsc_k = K
                rsc_successful_runs = len(combined_rescaled_sig[K])
    
    if not np.isinf(best_rsc_mse):
        total_possible = len(all_results) * 2
        comparison_data.append({
            'method': 'Rescaled_Signature',
            'best_MSE': best_rsc_mse,
            'optimal_K': best_rsc_k,
            'n_successful_runs': rsc_successful_runs,
            'success_rate': rsc_successful_runs / total_possible * 100
        })
    
    # Save method comparison
    comp_df = pd.DataFrame(comparison_data)
    comp_path = os.path.join(detailed_dir, 'combined_method_comparison.csv')
    comp_df.to_csv(comp_path, index=False)
    logger.info(f"Saved method comparison data to {comp_path}")
    
    logger.info(f"All combined landscape data saved to {detailed_dir}/")


def _generate_combined_regime_analysis(all_results: Dict, save_dir: str = 'plots/regime_studies'):
    """
    Generate combined regime analysis treating all regimes as a single experiment.
    
    Args:
        all_results: Dictionary of regime results
        save_dir: Directory to save combined analysis
    """
    logger.info("Generating combined regime analysis...")
    
    # Combine all results into aggregate statistics
    combined_data = {
        'total_monte_carlo_runs': 0,
        'regime_count': len(all_results),
        'enhanced_mle_performance': [],
        'expected_sig_performance': [],
        'rescaled_sig_performance': [],
        'regime_names': list(all_results.keys())
    }
    
    # Aggregate performance across all regimes
    for regime_name, results in all_results.items():
        # Enhanced MLE performance
        enhanced_mle_mse = _get_all_enhanced_mle_mse(results)
        if enhanced_mle_mse > 0:
            combined_data['enhanced_mle_performance'].append(enhanced_mle_mse)
        
        # Count total Monte Carlo runs
        enhanced_mle_data = results.get('enhanced_mle_mse', []) if isinstance(results, dict) else getattr(results, 'enhanced_mle_mse', [])
        if enhanced_mle_data:
            combined_data['total_monte_carlo_runs'] += len(enhanced_mle_data)
        
        # Get signature method data (handle both dict and object formats)
        expected_sig_data = results.get('expected_sig_mse', {}) if isinstance(results, dict) else getattr(results, 'expected_sig_mse', {})
        rescaled_sig_data = results.get('rescaled_sig_mse', {}) if isinstance(results, dict) else getattr(results, 'rescaled_sig_mse', {})
        
        # Best signature method performance
        best_exp = float('inf')
        for K in expected_sig_data:
            if expected_sig_data[K]:
                valid_mses = [x for x in expected_sig_data[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_exp:
                        best_exp = mean_mse
        if not np.isinf(best_exp):
            combined_data['expected_sig_performance'].append(best_exp)
        
        best_rsc = float('inf')
        for K in rescaled_sig_data:
            if rescaled_sig_data[K]:
                valid_mses = [x for x in rescaled_sig_data[K] if not np.isnan(x)]
                if valid_mses:
                    mean_mse = np.mean(valid_mses)
                    if mean_mse < best_rsc:
                        best_rsc = mean_mse
        if not np.isinf(best_rsc):
            combined_data['rescaled_sig_performance'].append(best_rsc)
    
    # Calculate overall statistics
    if combined_data['enhanced_mle_performance']:
        overall_mle_mse = np.mean(combined_data['enhanced_mle_performance'])
        overall_exp_mse = np.mean(combined_data['expected_sig_performance']) if combined_data['expected_sig_performance'] else float('inf')
        overall_rsc_mse = np.mean(combined_data['rescaled_sig_performance']) if combined_data['rescaled_sig_performance'] else float('inf')
        
        exp_improvement = (1 - overall_exp_mse/overall_mle_mse) * 100 if overall_mle_mse > 0 else 0
        rsc_improvement = (1 - overall_rsc_mse/overall_mle_mse) * 100 if overall_mle_mse > 0 else 0
        
        # Save combined analysis results
        combined_summary = {
            'total_regimes': combined_data['regime_count'],
            'total_monte_carlo_runs': combined_data['total_monte_carlo_runs'],
            'overall_enhanced_mle_mse': overall_mle_mse,
            'overall_expected_sig_mse': overall_exp_mse,
            'overall_rescaled_sig_mse': overall_rsc_mse,
            'expected_sig_improvement_pct': exp_improvement,
            'rescaled_sig_improvement_pct': rsc_improvement,
            'regimes_analyzed': ', '.join(combined_data['regime_names'])
        }
        
        # Save to CSV
        combined_df = pd.DataFrame([combined_summary])
        combined_path = os.path.join(save_dir, 'detailed_results', 'combined_regime_analysis.csv')
        os.makedirs(os.path.dirname(combined_path), exist_ok=True)
        combined_df.to_csv(combined_path, index=False)
        logger.info(f"Saved combined regime analysis to {combined_path}")
        
        # Generate combined landscape visualization
        _generate_combined_landscape_plot(all_results, save_dir)
        
        # Log summary
        logger.info(f"\nCOMBINED REGIME ANALYSIS SUMMARY:")
        logger.info(f"  Total regimes analyzed: {combined_data['regime_count']}")
        logger.info(f"  Total Monte Carlo runs: {combined_data['total_monte_carlo_runs']}")
        logger.info(f"  Overall Enhanced MLE MSE: {overall_mle_mse:.4f}")
        logger.info(f"  Overall Expected Sig MSE: {overall_exp_mse:.4f} ({exp_improvement:+.1f}%)")
        logger.info(f"  Overall Rescaled Sig MSE: {overall_rsc_mse:.4f} ({rsc_improvement:+.1f}%)")


if __name__ == "__main__":
    # Test with a single regime first
    logger.info("Testing with single regime: Slow Reversion, Low Volatility")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Test single regime with 2 Monte Carlo runs
    experiment = RegimeOptimizationExperiment(
        regime_name="Slow Reversion, Low Volatility",
        n_monte_carlo=2,
        device=device,
        config=ConfigPresets.optimized()
    )
    
    results = experiment.run_regime_experiment()
    experiment.plot_regime_landscape(results)
    experiment.save_regime_results(results)
    
    logger.info("Single regime test completed successfully!")